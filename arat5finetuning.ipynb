{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### [T5](https://github.com/google-research/text-to-text-transfer-transformer)\n- **Text-To-Text Transfer Transformer**\n- A unified framework that converts every language problem into a text-to-text format.\n- Achieves state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more.\n\n### Multi Class vs Multi Label Classification\n- **Multi Class** - There are multiple categories but each instance is assigned only one, therefore such problems are known as multi-class classification problem.","metadata":{"id":"buleZD1j2kLm"}},{"cell_type":"markdown","source":"# Imports","metadata":{"id":"vr-nvX_HT4_K"}},{"cell_type":"markdown","source":"The entire code is written using **PyTorch**.<br>\nWe'll be using the **transformers** library by [huggingface](https://github.com/huggingface/transformers) as they provide wrappers for multiple Transformer models.","metadata":{"id":"GqOpA5x73pYs"}},{"cell_type":"code","source":"%%capture\n\n!pip install transformers\n!pip install pytorch-lightning --upgrade\n!pip install sentencepiece\n!pip install datasets --upgrade\n!pip install torchmetrics\n!pip install wandb\n!pip install lightning","metadata":{"id":"9J7Ws11-9PqG","execution":{"iopub.status.busy":"2023-08-28T19:49:09.730041Z","iopub.execute_input":"2023-08-28T19:49:09.730480Z","iopub.status.idle":"2023-08-28T19:50:39.135731Z","shell.execute_reply.started":"2023-08-28T19:49:09.730454Z","shell.execute_reply":"2023-08-28T19:50:39.134438Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"'''rom google.colab import files\n\nfiles.upload()\n! mkdir ~/.kaggle\n! cp kaggle.json ~/.kaggle/\n! chmod 600 ~/.kaggle/kaggle.json\n! kaggle datasets download -d sifalklioui/hatespeechdza\n!mkdir data\n!unzip hatespeechdza.zip -d ./data'''","metadata":{"id":"61f6obyD_Kud","outputId":"63cd297c-7f38-4c70-d1fa-1b644585edc1","execution":{"iopub.status.busy":"2023-08-28T08:18:42.855515Z","iopub.execute_input":"2023-08-28T08:18:42.855907Z","iopub.status.idle":"2023-08-28T08:18:42.864662Z","shell.execute_reply.started":"2023-08-28T08:18:42.855871Z","shell.execute_reply":"2023-08-28T08:18:42.863740Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'rom google.colab import files\\n\\nfiles.upload()\\n! mkdir ~/.kaggle\\n! cp kaggle.json ~/.kaggle/\\n! chmod 600 ~/.kaggle/kaggle.json\\n! kaggle datasets download -d sifalklioui/hatespeechdza\\n!mkdir data\\n!unzip hatespeechdza.zip -d ./data'"},"metadata":{}}]},{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2","metadata":{"execution":{"iopub.status.busy":"2023-08-28T19:51:29.823611Z","iopub.execute_input":"2023-08-28T19:51:29.824895Z","iopub.status.idle":"2023-08-28T19:51:30.000114Z","shell.execute_reply.started":"2023-08-28T19:51:29.824838Z","shell.execute_reply":"2023-08-28T19:51:29.999157Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset as hgdataset\nfrom datasets import load_dataset\nimport numpy as np\nimport pickle\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport copy\nfrom tqdm.notebook import tqdm\nimport gc\nimport random\nimport torch\nimport wandb\nimport torchmetrics\nimport logging\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom dataclasses import dataclass\nfrom sklearn.metrics import f1_score\nimport pytorch_lightning as pl\nfrom torch.optim import AdamW\nfrom sklearn import metrics\nfrom lightning.pytorch.loggers import WandbLogger\n\nfrom transformers import (\n    T5Tokenizer,\n    T5Model,\n    T5ForConditionalGeneration,\n    get_linear_schedule_with_warmup\n)\nwandb.login(key=\"902ffdfbd80732219ee9853892860a048fa9914f\")\nwandb_logger = WandbLogger(project=\"HTarabT5\")","metadata":{"id":"07GPLpCt_AjQ","execution":{"iopub.status.busy":"2023-08-28T19:50:39.138005Z","iopub.execute_input":"2023-08-28T19:50:39.138380Z","iopub.status.idle":"2023-08-28T19:51:29.819191Z","shell.execute_reply.started":"2023-08-28T19:50:39.138342Z","shell.execute_reply":"2023-08-28T19:51:29.818266Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msifalklioui\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.8 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>./wandb/run-20230828_195057-k1y48tth</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/sifalklioui/HTarabT5/runs/k1y48tth' target=\"_blank\">copper-blaze-45</a></strong> to <a href='https://wandb.ai/sifalklioui/HTarabT5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/sifalklioui/HTarabT5' target=\"_blank\">https://wandb.ai/sifalklioui/HTarabT5</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/sifalklioui/HTarabT5/runs/k1y48tth' target=\"_blank\">https://wandb.ai/sifalklioui/HTarabT5/runs/k1y48tth</a>"},"metadata":{}}]},{"cell_type":"code","source":"@dataclass\nclass Config:\n    seed = 203\n    data_folder = \"../input/hatespeechdza\"\n    output_dir = './logs'\n    model_name_or_path = 'UBC-NLP/AraT5v2-base-1024'\n    src_max_length = 40\n    tgt_max_length = 2\n    add_special_tokens = True\n    truncation = True\n    return_tensors = 'pt'\n    padding = \"max_length\"\n    weight_decay=0.0\n    adam_epsilon=1e-8\n    warmup_steps=0\n    train_batch_size=48\n    eval_batch_size=48\n    num_train_epochs=5\n    gradient_accumulation_steps=16\n    n_gpu=1\n    fp_16= False, # if you want to enable 16-bit training then install apex and set this to true\n    max_grad_norm=0.5 # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n    learning_rate= float(3e-4)\n\nconfig = Config()","metadata":{"id":"281L6wVJ6oHj","execution":{"iopub.status.busy":"2023-08-28T19:51:33.152342Z","iopub.execute_input":"2023-08-28T19:51:33.152787Z","iopub.status.idle":"2023-08-28T19:51:33.404169Z","shell.execute_reply.started":"2023-08-28T19:51:33.152749Z","shell.execute_reply":"2023-08-28T19:51:33.402990Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\nset_seed(config.seed)","metadata":{"id":"8_WV69kk6oHk","execution":{"iopub.status.busy":"2023-08-28T19:51:40.210025Z","iopub.execute_input":"2023-08-28T19:51:40.210474Z","iopub.status.idle":"2023-08-28T19:51:40.387342Z","shell.execute_reply.started":"2023-08-28T19:51:40.210439Z","shell.execute_reply":"2023-08-28T19:51:40.386431Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Dataset & Dataloader","metadata":{"id":"e1AhmXnXByg5"}},{"cell_type":"markdown","source":"Now, we'll create a custom Dataset class inherited from the PyTorch Dataset class. We'll be using the **T5 tokenizer** that returns **input_ids** and **attention_mask**.<br><br>\nThe custom Dataset class will return a dict containing - <br>\n\n- src_input_ids\n- src_attention_mask\n- tgt_input_ids'\n-tgt_attention_mask","metadata":{"id":"cwrzxPV8B1Es"}},{"cell_type":"code","source":"class HateDetect():\n    def __init__(self,config,tokenizer, part):\n\n        self.config = config\n        self.part = part\n        self.tokenizer = tokenizer\n\n\n        data_paths = {\n            'train': config.data_folder + \"/dataset_prep_train.csv\",\n            'test': config.data_folder + \"/dataset_prep_test.csv\",\n            'val': config.data_folder + \"/dataset_prep_val.csv\"\n        }\n        path = data_paths.get(self.part,None)\n        if path is not None:\n            df = pd.read_csv(path)\n            df['label'].replace({0:\"normal\",1:\"hate\"}, inplace = True)\n            self.data = hgdataset.from_pandas(df ,split=self.part)\n        else:\n            raise ValueError(\"Invalid value for self.part\")\n\n\n        self.dataset_scr,self.dataset_tgt = self.tokenize()\n\n        # create funtion to tokenize data\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self,idx):\n\n        source_ids = self.dataset_scr[\"input_ids\"][idx].squeeze()\n        target_ids = self.dataset_tgt[\"input_ids\"][idx].squeeze()\n\n        src_mask    = self.dataset_scr[\"attention_mask\"][idx].squeeze()\n        target_mask = self.dataset_tgt[\"attention_mask\"][idx].squeeze()\n\n        return {\"source_ids\": source_ids,\n                \"source_mask\": src_mask,\n                \"target_ids\": target_ids,\n                \"target_mask\": target_mask}\n\n\n    def tokenize(self):\n\n        tokenizer_params = {\n            \"src\": {\n                \"max_length\": self.config.src_max_length,\n                \"add_special_tokens\": self.config.add_special_tokens,\n                \"truncation\": self.config.truncation,\n                \"return_tensors\": self.config.return_tensors,\n                \"padding\": self.config.padding\n            },\n            \"tgt\": {\n                \"max_length\": self.config.tgt_max_length,\n                \"add_special_tokens\": self.config.add_special_tokens,\n                \"truncation\": self.config.truncation,\n                \"return_tensors\": self.config.return_tensors,\n                \"padding\": self.config.padding\n            }\n        }\n        dataset_scr = self.tokenizer(self.data['text'], **tokenizer_params[\"src\"])\n        dataset_tgt = self.tokenizer(self.data['label'], **tokenizer_params[\"tgt\"])\n        return dataset_scr,dataset_tgt\n\ndef get_dataset(config,tokenizer,part):\n    return HateDetect(config,tokenizer,part)","metadata":{"id":"w0D46GkV6oHl","execution":{"iopub.status.busy":"2023-08-28T19:51:42.710030Z","iopub.execute_input":"2023-08-28T19:51:42.710449Z","iopub.status.idle":"2023-08-28T19:51:42.883996Z","shell.execute_reply.started":"2023-08-28T19:51:42.710415Z","shell.execute_reply":"2023-08-28T19:51:42.883071Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"get_dataset","metadata":{"execution":{"iopub.status.busy":"2023-08-28T08:19:32.928544Z","iopub.execute_input":"2023-08-28T08:19:32.931519Z","iopub.status.idle":"2023-08-28T08:19:32.944105Z","shell.execute_reply.started":"2023-08-28T08:19:32.931485Z","shell.execute_reply":"2023-08-28T08:19:32.943175Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<function __main__.get_dataset(config, tokenizer, part)>"},"metadata":{}}]},{"cell_type":"code","source":"logger = logging.getLogger(__name__)\n\nclass DeviceCallback(pl.Callback):\n    def on_batch_start(self, trainer, pl_module):\n        assert next(pl_module.parameters()).device.type == \"cuda\"\n\nclass LoggingCallback(pl.Callback):\n    def on_validation_end(self, trainer, pl_module):\n        logger.info(\"***** Validation results *****\")\n        if pl_module.is_logger():\n            metrics = trainer.callback_metrics\n            # Log results\n            for key in sorted(metrics):\n                if key not in [\"log\", \"progress_bar\"]:\n                    logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n\n\n    ","metadata":{"id":"BGVTpK7g6oHl","execution":{"iopub.status.busy":"2023-08-28T08:19:32.948526Z","iopub.execute_input":"2023-08-28T08:19:32.950719Z","iopub.status.idle":"2023-08-28T08:19:32.960990Z","shell.execute_reply.started":"2023-08-28T08:19:32.950686Z","shell.execute_reply":"2023-08-28T08:19:32.960023Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"    def on_test_end(self, trainer, pl_module):\n        logger.info(\"***** Validation results *****\")\n        if pl_module.is_logger():\n            metrics = trainer.callback_metrics\n            # Log results\n            for key in sorted(metrics):\n                if key not in [\"log\", \"progress_bar\"]:\n                    logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))","metadata":{"execution":{"iopub.status.busy":"2023-08-28T08:19:32.965694Z","iopub.execute_input":"2023-08-28T08:19:32.968143Z","iopub.status.idle":"2023-08-28T08:19:32.976653Z","shell.execute_reply.started":"2023-08-28T08:19:32.968107Z","shell.execute_reply":"2023-08-28T08:19:32.975769Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"callbacks=[DeviceCallback()]","metadata":{"execution":{"iopub.status.busy":"2023-08-28T08:19:32.985579Z","iopub.execute_input":"2023-08-28T08:19:32.987759Z","iopub.status.idle":"2023-08-28T08:19:32.994150Z","shell.execute_reply.started":"2023-08-28T08:19:32.987726Z","shell.execute_reply":"2023-08-28T08:19:32.993265Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"checkpoint_callback = pl.callbacks.ModelCheckpoint(\n    dirpath= config.output_dir, monitor=\"validation_epoch_average\", mode=\"max\", save_top_k=1)\n    \ndc = pl.callbacks.DeviceStatsMonitor(cpu_stats=True)\n\ntrain_params = dict(\n    devices=config.n_gpu,\n    strategy=\"auto\",\n    accelerator=\"gpu\",\n    max_epochs=config.num_train_epochs,\n    precision= \"16-mixed\",\n    gradient_clip_val=config.max_grad_norm,\n    \n)","metadata":{"id":"U9tLgD2O6oHl","execution":{"iopub.status.busy":"2023-08-28T19:51:59.291669Z","iopub.execute_input":"2023-08-28T19:51:59.292040Z","iopub.status.idle":"2023-08-28T19:51:59.415121Z","shell.execute_reply.started":"2023-08-28T19:51:59.292007Z","shell.execute_reply":"2023-08-28T19:51:59.414101Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"LoggingCallback(),checkpoint_callback,    callbacks=[checkpoint_callback]","metadata":{"execution":{"iopub.status.busy":"2023-08-28T08:19:33.023267Z","iopub.execute_input":"2023-08-28T08:19:33.025461Z","iopub.status.idle":"2023-08-28T08:19:33.049108Z","shell.execute_reply.started":"2023-08-28T08:19:33.025427Z","shell.execute_reply":"2023-08-28T08:19:33.046293Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[91m╭──────────────────────────────────────────────────────────────────────────────────────────────────╮\u001b[0m\n\u001b[91m│\u001b[0m \u001b[1;35mLoggingCallback\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m,checkpoint_callback,    \u001b[33mcallbacks\u001b[0m=\u001b[1m[\u001b[0mcheckpoint_callback\u001b[1m]\u001b[0m                        \u001b[91m│\u001b[0m\n\u001b[91m│\u001b[0m                                           \u001b[1;91m▲\u001b[0m                                                      \u001b[91m│\u001b[0m\n\u001b[91m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mSyntaxError: \u001b[0minvalid syntax. Maybe you meant \u001b[32m'=='\u001b[0m or \u001b[32m':='\u001b[0m instead of \u001b[32m'='\u001b[0m?\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭──────────────────────────────────────────────────────────────────────────────────────────────────╮</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LoggingCallback</span><span style=\"font-weight: bold\">()</span>,checkpoint_callback,    <span style=\"color: #808000; text-decoration-color: #808000\">callbacks</span>=<span style=\"font-weight: bold\">[</span>checkpoint_callback<span style=\"font-weight: bold\">]</span>                        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">▲</span>                                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">SyntaxError: </span>invalid syntax. Maybe you meant <span style=\"color: #008000; text-decoration-color: #008000\">'=='</span> or <span style=\"color: #008000; text-decoration-color: #008000\">':='</span> instead of <span style=\"color: #008000; text-decoration-color: #008000\">'='</span>?\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"feB5OEdeoV91"}},{"cell_type":"markdown","source":"Coming to the most interesting part - the model architecture! We'll create a class named **Model**, inherited from **torch.nn.Module**.<br><br>\n\n### Flow\n- We initialize our pretrained T5 model with a Conditional Generation Head.\n- Pass in the src & tgt, input_ids & attention_mask.\n- The model returns the decoder generated output ids (predicted labels in textual format), which we need to decode further using the tokenizer.","metadata":{"id":"HjqZhSB8C0Qk"}},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-08-28T12:55:11.280165Z","iopub.execute_input":"2023-08-28T12:55:11.280600Z","iopub.status.idle":"2023-08-28T12:55:11.778439Z","shell.execute_reply.started":"2023-08-28T12:55:11.280564Z","shell.execute_reply":"2023-08-28T12:55:11.777024Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"torch.cuda.empty_cache() ","metadata":{"execution":{"iopub.status.busy":"2023-08-28T12:55:13.674373Z","iopub.execute_input":"2023-08-28T12:55:13.674752Z","iopub.status.idle":"2023-08-28T12:55:13.683781Z","shell.execute_reply.started":"2023-08-28T12:55:13.674720Z","shell.execute_reply":"2023-08-28T12:55:13.682432Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"%memit","metadata":{"execution":{"iopub.status.busy":"2023-08-28T12:56:50.778247Z","iopub.execute_input":"2023-08-28T12:56:50.778637Z","iopub.status.idle":"2023-08-28T12:56:51.554483Z","shell.execute_reply.started":"2023-08-28T12:56:50.778604Z","shell.execute_reply":"2023-08-28T12:56:51.553365Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"peak memory: 8702.57 MiB, increment: 0.00 MiB\n","output_type":"stream"}]},{"cell_type":"code","source":"%load_ext memory_profiler\n\n%memit","metadata":{"execution":{"iopub.status.busy":"2023-08-28T12:56:41.409459Z","iopub.execute_input":"2023-08-28T12:56:41.409842Z","iopub.status.idle":"2023-08-28T12:56:42.138799Z","shell.execute_reply.started":"2023-08-28T12:56:41.409812Z","shell.execute_reply":"2023-08-28T12:56:42.137406Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"The memory_profiler extension is already loaded. To reload it, use:\n  %reload_ext memory_profiler\npeak memory: 8702.45 MiB, increment: 0.00 MiB\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class T5FineTuner(pl.LightningModule):\n    def __init__(self, config):\n        super().__init__()\n        gc.collect()\n        torch.cuda.empty_cache() \n        self.config = config\n        self.model = T5ForConditionalGeneration.from_pretrained(config.model_name_or_path)\n        self.tokenizer = T5Tokenizer.from_pretrained(config.model_name_or_path)\n        self.training_step_outputs = []\n        self.validation_step_outputs = []\n        self.outputs_ids = []\n        self.targets_ids = []\n\n    def forward(\n        self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, labels=None\n        ):\n        return self.model(\n            input_ids,\n            attention_mask=attention_mask,\n            decoder_input_ids=decoder_input_ids,\n            decoder_attention_mask=decoder_attention_mask,\n            labels=labels,\n            )\n\n    def _step(self, batch):\n        lm_labels = batch[\"target_ids\"]\n        lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n        outputs = self(\n        input_ids=batch[\"source_ids\"],\n        attention_mask=batch[\"source_mask\"],\n        labels=lm_labels,\n        decoder_attention_mask=batch['target_mask']\n        )\n        del lm_labels\n        return outputs[0]\n\n    def training_step(self, batch, batch_idx):\n        loss = self._step(batch)\n        #self.log(\"train/loss\", loss)\n        self.training_step_outputs.append(loss.item())\n        return loss\n\n    def on_train_epoch_end(self):\n        self.log(\"training_epoch_average\", np.mean(self.training_step_outputs), sync_dist=True, prog_bar=True, logger=True, on_epoch=True)\n        self.training_step_outputs.clear()  # free memory\n    def validation_step(self, batch, batch_idx):\n        \n        pred_ids = self.model.generate(input_ids = batch['input_ids'],\n                                       attention_mask=batch['source_mask'],\n                                       max_length=2\n        )\n        self.targets_ids.extend(batch['target_ids'][:,0])\n        self.outputs_ids.extend(pred_ids[:,0])\n        del pred_ids\n        \n    def on_validation_end(self):\n        \n        # to complete \n        # toughts: doesn't matter what the source id is \n        # try to track how much epochs until the gens[:,0] are of these two classes\n        # look into how to make custom metrics \n        \n        \n    def configure_optimizers(self):\n        \"Prepare optimizer and schedule (linear warmup and decay)\"\n\n        no_decay = [\"bias\", \"LayerNorm.weight\"]\n\n        optimizer_grouped_parameters = [\n        {\n            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n            \"weight_decay\": self.config.weight_decay,\n        },\n        {\n            \"params\": [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)],\n            \"weight_decay\": 0.0,\n        },\n        ]\n        optimizer = AdamW(optimizer_grouped_parameters, lr=self.config.learning_rate, eps=self.config.adam_epsilon)\n        scheduler = get_linear_schedule_with_warmup(\n        optimizer, num_warmup_steps=self.config.warmup_steps, num_training_steps=self.trainer.estimated_stepping_batches)\n        del optimizer_grouped_parameters\n        gc.collect()\n        return [optimizer],[scheduler]\n\n\n    def train_dataloader(self):\n        return DataLoader(get_dataset(config=self.config, tokenizer=self.tokenizer, part=\"train\"), batch_size=self.config.train_batch_size, drop_last=True, shuffle=True,num_workers=0)\n    def val_dataloader(self):\n        return DataLoader(get_dataset(config=self.config,tokenizer=self.tokenizer, part=\"val\"), batch_size=self.config.eval_batch_size, drop_last=True,num_workers=0)\n","metadata":{"id":"d1xG8CCdlgge","_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-08-28T12:57:36.630074Z","iopub.execute_input":"2023-08-28T12:57:36.630441Z","iopub.status.idle":"2023-08-28T12:57:36.649336Z","shell.execute_reply.started":"2023-08-28T12:57:36.630410Z","shell.execute_reply":"2023-08-28T12:57:36.648251Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-08-28T08:19:33.080339Z","iopub.status.idle":"2023-08-28T08:19:33.081154Z","shell.execute_reply.started":"2023-08-28T08:19:33.080905Z","shell.execute_reply":"2023-08-28T08:19:33.080930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_dataloader(self):\n    val_dataset = get_dataset(config=self.config,tokenizer=self.tokenizer, part=\"test\")\n    return DataLoader(val_dataset, batch_size=self.config.eval_batch_size,drop_last=True, num_workers=1)","metadata":{"execution":{"iopub.status.busy":"2023-08-28T08:19:33.082544Z","iopub.status.idle":"2023-08-28T08:19:33.083334Z","shell.execute_reply.started":"2023-08-28T08:19:33.083070Z","shell.execute_reply":"2023-08-28T08:19:33.083095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_step(self, batch, batch_idx):\n        loss = self._step(batch)\n        self.test_step_outputs.append(loss)\n        return loss\n\ndef on_test_epoch_end(self):\n    epoch_average = torch.stack(self.test_step_outputs).mean()\n    self.log(\"test_epoch_average\", epoch_average,  sync_dist=True, prog_bar=True, logger=True, on_epoch=True)\n    self.test_step_outputs.clear()  # free memory\n","metadata":{"execution":{"iopub.status.busy":"2023-08-28T08:19:33.091708Z","iopub.status.idle":"2023-08-28T08:19:33.092476Z","shell.execute_reply.started":"2023-08-28T08:19:33.092218Z","shell.execute_reply":"2023-08-28T08:19:33.092258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"        #self.outputsf1.append(outs.detach().tolist())\n        #self.targetsf1.append(target.detach().tolist())","metadata":{"execution":{"iopub.status.busy":"2023-08-28T08:19:33.093858Z","iopub.status.idle":"2023-08-28T08:19:33.094613Z","shell.execute_reply.started":"2023-08-28T08:19:33.094369Z","shell.execute_reply":"2023-08-28T08:19:33.094393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#target_binary = mlb.fit_transform(self.targetsf1)\n        #output_binary = mlb.transform(self.outputsf1)\n        \n        \n        #out_flat = [pair[0] for sublist in self.outputsf1 for pair in sublist]\n        #target_flat = [pair[0] for sublist in self.targetsf1 for pair in sublist]\n        #targets = [ids[0] for batch in self.targetsf1 for ids in batch]\n        #outputs = [ids[0] for batch in self.outputsf1 for ids in batch]\n        \n        #f1 = f1_score(targets,outputs,average='macro')\n        #self.log(\"validation_f1_step\",float(0.5) ,  sync_dist=True, prog_bar=True, logger=True, on_epoch=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-28T08:19:33.095974Z","iopub.status.idle":"2023-08-28T08:19:33.096754Z","shell.execute_reply.started":"2023-08-28T08:19:33.096512Z","shell.execute_reply":"2023-08-28T08:19:33.096536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = T5FineTuner(config)","metadata":{"id":"jiypz6jrG9bl","outputId":"d16d6835-314f-4c02-842f-0962de051474","execution":{"iopub.status.busy":"2023-08-28T12:57:41.803597Z","iopub.execute_input":"2023-08-28T12:57:41.803994Z","iopub.status.idle":"2023-08-28T12:57:50.200386Z","shell.execute_reply.started":"2023-08-28T12:57:41.803959Z","shell.execute_reply":"2023-08-28T12:57:50.199151Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"\ntrainer = pl.Trainer(**train_params)","metadata":{"id":"mlsnd6mu6oHn","outputId":"dfe6f12c-9dda-483b-b4e8-5f8056df362b","execution":{"iopub.status.busy":"2023-08-28T12:58:13.215102Z","iopub.execute_input":"2023-08-28T12:58:13.216334Z","iopub.status.idle":"2023-08-28T12:58:13.341771Z","shell.execute_reply.started":"2023-08-28T12:58:13.216287Z","shell.execute_reply":"2023-08-28T12:58:13.340692Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"INFO: Using 16bit Automatic Mixed Precision (AMP)\nINFO: Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\nINFO: GPU available: True (cuda), used: True\nINFO: TPU available: False, using: 0 TPU cores\nINFO: IPU available: False, using: 0 IPUs\nINFO: HPU available: False, using: 0 HPUs\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.fit(model)","metadata":{"id":"iZ59dtmH6oHo","outputId":"b6530313-d689-4dc7-829e-24b7c9c333e6","execution":{"iopub.status.busy":"2023-08-28T12:58:15.432952Z","iopub.execute_input":"2023-08-28T12:58:15.433321Z","iopub.status.idle":"2023-08-28T13:05:11.100668Z","shell.execute_reply.started":"2023-08-28T12:58:15.433291Z","shell.execute_reply":"2023-08-28T13:05:11.099373Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /kaggle/working/lightning_logs/version_0/checkpoints exists and is not empty.\n  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\nINFO: Loading `train_dataloader` to estimate number of stepping batches.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e79c660b0f0e48db9a92a69a66a251d0"}},"metadata":{}},{"name":"stderr","text":"INFO: `Trainer.fit` stopped: `max_epochs=5` reached.\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = T5Tokenizer.from_pretrained(config.model_name_or_path)","metadata":{"id":"QEVJPRXWgnZw","execution":{"iopub.status.busy":"2023-08-28T08:19:33.111207Z","iopub.status.idle":"2023-08-28T08:19:33.111980Z","shell.execute_reply.started":"2023-08-28T08:19:33.111726Z","shell.execute_reply":"2023-08-28T08:19:33.111750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_ = HateDetect(config,tokenizer=tokenizer, part=\"test\")\nloader = DataLoader(data_, batch_size=config.eval_batch_size,drop_last=True, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2023-08-28T08:19:33.113312Z","iopub.status.idle":"2023-08-28T08:19:33.114067Z","shell.execute_reply.started":"2023-08-28T08:19:33.113819Z","shell.execute_reply":"2023-08-28T08:19:33.113853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del batch","metadata":{"execution":{"iopub.status.busy":"2023-08-28T08:19:33.115446Z","iopub.status.idle":"2023-08-28T08:19:33.116222Z","shell.execute_reply.started":"2023-08-28T08:19:33.115982Z","shell.execute_reply":"2023-08-28T08:19:33.116006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"/kaggle/working/logs/epoch=0-step=117.ckpt\"\nmodel_test = T5FineTuner.load_from_checkpoint(path,config=config)\n\n# disable randomness, dropout, etc...\nmodel_test.eval()\n\noutputs = []\ntargets = []\nfor batch in tqdm(loader):\n    outs = model_test.model.generate(input_ids=batch['source_ids'].cuda(),\n                              attention_mask=batch['source_mask'].cuda(),\n                              max_length=2)\n\n    dec = [tokenizer.decode(ids[ids > 1 ]) for ids in outs]\n    target = [tokenizer.decode((ids[ids > 1 ])) for ids in batch[\"target_ids\"]]\n\n    outputs.extend(dec)\n    targets.extend(target)","metadata":{"id":"MEa00VKtVQq-","outputId":"1df2ef83-00d2-4fd1-ddc5-8cfe603f9a7f","execution":{"iopub.status.busy":"2023-08-28T08:19:33.117604Z","iopub.status.idle":"2023-08-28T08:19:33.118416Z","shell.execute_reply.started":"2023-08-28T08:19:33.118153Z","shell.execute_reply":"2023-08-28T08:19:33.118177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(metrics.classification_report(targets, outputs))","metadata":{"id":"hCOjxCSbVSY2","outputId":"6f3cc0be-79dc-4cbb-8fba-f1bcfd7df838","execution":{"iopub.status.busy":"2023-08-28T08:19:33.119847Z","iopub.status.idle":"2023-08-28T08:19:33.120688Z","shell.execute_reply.started":"2023-08-28T08:19:33.120395Z","shell.execute_reply":"2023-08-28T08:19:33.120419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import textwrap","metadata":{"id":"3gqbs7XaECCm","execution":{"iopub.status.busy":"2023-08-28T08:19:33.122068Z","iopub.status.idle":"2023-08-28T08:19:33.122864Z","shell.execute_reply.started":"2023-08-28T08:19:33.122611Z","shell.execute_reply":"2023-08-28T08:19:33.122634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(32):\n    lines = textwrap.wrap(\"Review:\\n%s\\n\" % texts[i], width=100)\n    print(\"\\n\".join(lines))\n    print(\"\\nActual sentiment: %s\" % targets[i])\n    print(\"Predicted sentiment: %s\" % dec[i])\n    print(\"=====================================================================\\n\")","metadata":{"id":"7sw2flRKD-Ee","execution":{"iopub.status.busy":"2023-08-28T08:19:33.124276Z","iopub.status.idle":"2023-08-28T08:19:33.125086Z","shell.execute_reply.started":"2023-08-28T08:19:33.124842Z","shell.execute_reply":"2023-08-28T08:19:33.124867Z"},"trusted":true},"execution_count":null,"outputs":[]}]}