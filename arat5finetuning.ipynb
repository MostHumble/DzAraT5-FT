{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### [T5](https://github.com/google-research/text-to-text-transfer-transformer)\n- **Text-To-Text Transfer Transformer**\n- A unified framework that converts every language problem into a text-to-text format.\n- Achieves state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more.\n\n### Multi Class vs Multi Label Classification\n- **Multi Class** - There are multiple categories but each instance is assigned only one, therefore such problems are known as multi-class classification problem.","metadata":{"id":"buleZD1j2kLm"}},{"cell_type":"markdown","source":"# Imports","metadata":{"id":"vr-nvX_HT4_K"}},{"cell_type":"markdown","source":"The entire code is written using **PyTorch**.<br>\nWe'll be using the **transformers** library by [huggingface](https://github.com/huggingface/transformers) as they provide wrappers for multiple Transformer models.","metadata":{"id":"GqOpA5x73pYs"}},{"cell_type":"code","source":"%%capture\n\n!pip install transformers\n!pip install pytorch-lightning --upgrade\n!pip install sentencepiece\n!pip install datasets --upgrade\n!pip install torchmetrics\n!pip install wandb\n!pip install lightning","metadata":{"id":"9J7Ws11-9PqG","execution":{"iopub.status.busy":"2023-08-26T20:23:16.667347Z","iopub.execute_input":"2023-08-26T20:23:16.667875Z","iopub.status.idle":"2023-08-26T20:24:46.842480Z","shell.execute_reply.started":"2023-08-26T20:23:16.667834Z","shell.execute_reply":"2023-08-26T20:24:46.841159Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"'''rom google.colab import files\n\nfiles.upload()\n! mkdir ~/.kaggle\n! cp kaggle.json ~/.kaggle/\n! chmod 600 ~/.kaggle/kaggle.json\n! kaggle datasets download -d sifalklioui/hatespeechdza\n!mkdir data\n!unzip hatespeechdza.zip -d ./data'''","metadata":{"id":"61f6obyD_Kud","outputId":"63cd297c-7f38-4c70-d1fa-1b644585edc1","execution":{"iopub.status.busy":"2023-08-26T20:24:46.844975Z","iopub.execute_input":"2023-08-26T20:24:46.845982Z","iopub.status.idle":"2023-08-26T20:24:46.855026Z","shell.execute_reply.started":"2023-08-26T20:24:46.845938Z","shell.execute_reply":"2023-08-26T20:24:46.853981Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'rom google.colab import files\\n\\nfiles.upload()\\n! mkdir ~/.kaggle\\n! cp kaggle.json ~/.kaggle/\\n! chmod 600 ~/.kaggle/kaggle.json\\n! kaggle datasets download -d sifalklioui/hatespeechdza\\n!mkdir data\\n!unzip hatespeechdza.zip -d ./data'"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pickle\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport copy\nfrom tqdm.notebook import tqdm\nimport gc\nimport random\nimport torch\nimport torchmetrics\nimport logging\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom dataclasses import dataclass\nfrom sklearn.metrics import f1_score\nimport pytorch_lightning as pl\nfrom torch.optim import AdamW\nfrom sklearn import metrics\nfrom lightning.pytorch.loggers import WandbLogger\n\nfrom transformers import (\n    T5Tokenizer,\n    T5Model,\n    T5ForConditionalGeneration,\n    get_linear_schedule_with_warmup\n)\n\"902ffdfbd80732219ee9853892860a048fa9914f\"\nwandb_logger = WandbLogger(project=\"HTarabT5\")","metadata":{"id":"07GPLpCt_AjQ","execution":{"iopub.status.busy":"2023-08-26T20:24:46.856653Z","iopub.execute_input":"2023-08-26T20:24:46.857783Z","iopub.status.idle":"2023-08-26T20:25:43.727084Z","shell.execute_reply.started":"2023-08-26T20:24:46.857745Z","shell.execute_reply":"2023-08-26T20:25:43.726194Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.8 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>./wandb/run-20230826_202512-5povhqxq</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/sifalklioui/HTarabT5/runs/5povhqxq' target=\"_blank\">winter-terrain-19</a></strong> to <a href='https://wandb.ai/sifalklioui/HTarabT5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/sifalklioui/HTarabT5' target=\"_blank\">https://wandb.ai/sifalklioui/HTarabT5</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/sifalklioui/HTarabT5/runs/5povhqxq' target=\"_blank\">https://wandb.ai/sifalklioui/HTarabT5/runs/5povhqxq</a>"},"metadata":{}}]},{"cell_type":"code","source":"@dataclass\nclass Config:\n    seed = 203\n    data_folder = \"../input/hatespeechdza\"\n    output_dir = './logs'\n    model_name_or_path = 'UBC-NLP/AraT5v2-base-1024'\n    src_max_length = 40\n    tgt_max_length = 2\n    add_special_tokens = True\n    truncation = True\n    return_tensors = 'pt'\n    padding = \"max_length\"\n    weight_decay=0.0\n    adam_epsilon=1e-8\n    warmup_steps=0\n    train_batch_size=64\n    eval_batch_size=10\n    num_train_epochs=1\n    gradient_accumulation_steps=16\n    n_gpu=2\n    fp_16= False, # if you want to enable 16-bit training then install apex and set this to true\n    max_grad_norm=1.0 # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n    learning_rate= float(3e-4)\n\nconfig = Config()","metadata":{"id":"281L6wVJ6oHj","execution":{"iopub.status.busy":"2023-08-26T20:25:43.732317Z","iopub.execute_input":"2023-08-26T20:25:43.733736Z","iopub.status.idle":"2023-08-26T20:25:43.742760Z","shell.execute_reply.started":"2023-08-26T20:25:43.733695Z","shell.execute_reply":"2023-08-26T20:25:43.741861Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\nset_seed(config.seed)","metadata":{"id":"8_WV69kk6oHk","execution":{"iopub.status.busy":"2023-08-26T20:25:43.744232Z","iopub.execute_input":"2023-08-26T20:25:43.744870Z","iopub.status.idle":"2023-08-26T20:25:43.776521Z","shell.execute_reply.started":"2023-08-26T20:25:43.744832Z","shell.execute_reply":"2023-08-26T20:25:43.775671Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Dataset & Dataloader","metadata":{"id":"e1AhmXnXByg5"}},{"cell_type":"markdown","source":"Now, we'll create a custom Dataset class inherited from the PyTorch Dataset class. We'll be using the **T5 tokenizer** that returns **input_ids** and **attention_mask**.<br><br>\nThe custom Dataset class will return a dict containing - <br>\n\n- src_input_ids\n- src_attention_mask\n- tgt_input_ids'\n-tgt_attention_mask","metadata":{"id":"cwrzxPV8B1Es"}},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset as hgdataset\nfrom datasets import load_dataset\n\nclass HateDetect():\n    def __init__(self,config,tokenizer, part):\n\n        self.config = config\n        self.part = part\n        self.tokenizer = tokenizer\n\n\n        data_paths = {\n            'train': config.data_folder + \"/dataset_prep_train.csv\",\n            'test': config.data_folder + \"/dataset_prep_test.csv\",\n            'val': config.data_folder + \"/dataset_prep_val.csv\"\n        }\n        path = data_paths.get(self.part,None)\n        if path is not None:\n            df = pd.read_csv(path)\n            df['label'].replace({0:\"normal\",1:\"hate\"}, inplace = True)\n            self.data = hgdataset.from_pandas(df ,split=self.part)\n        else:\n            raise ValueError(\"Invalid value for self.part\")\n\n\n        self.dataset_scr,self.dataset_tgt = self.tokenize()\n\n        # create funtion to tokenize data\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self,idx):\n\n        source_ids = self.dataset_scr[\"input_ids\"][idx].squeeze()\n        target_ids = self.dataset_tgt[\"input_ids\"][idx].squeeze()\n\n        src_mask    = self.dataset_scr[\"attention_mask\"][idx].squeeze()\n        target_mask = self.dataset_tgt[\"attention_mask\"][idx].squeeze()\n\n        return {\"source_ids\": source_ids,\n                \"source_mask\": src_mask,\n                \"target_ids\": target_ids,\n                \"target_mask\": target_mask}\n\n\n    def tokenize(self):\n\n        tokenizer_params = {\n            \"src\": {\n                \"max_length\": self.config.src_max_length,\n                \"add_special_tokens\": self.config.add_special_tokens,\n                \"truncation\": self.config.truncation,\n                \"return_tensors\": self.config.return_tensors,\n                \"padding\": self.config.padding\n            },\n            \"tgt\": {\n                \"max_length\": self.config.tgt_max_length,\n                \"add_special_tokens\": self.config.add_special_tokens,\n                \"truncation\": self.config.truncation,\n                \"return_tensors\": self.config.return_tensors,\n                \"padding\": self.config.padding\n            }\n        }\n        dataset_scr = self.tokenizer.batch_encode_plus(self.data['text'], **tokenizer_params[\"src\"])\n        dataset_tgt = self.tokenizer.batch_encode_plus(self.data['label'], **tokenizer_params[\"tgt\"])\n        return dataset_scr,dataset_tgt\n\ndef get_dataset(config,tokenizer,part):\n    return HateDetect(config,tokenizer,part)","metadata":{"id":"w0D46GkV6oHl","execution":{"iopub.status.busy":"2023-08-26T20:25:43.777857Z","iopub.execute_input":"2023-08-26T20:25:43.778387Z","iopub.status.idle":"2023-08-26T20:25:44.139859Z","shell.execute_reply.started":"2023-08-26T20:25:43.778354Z","shell.execute_reply":"2023-08-26T20:25:44.138909Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"logger = logging.getLogger(__name__)\n\nclass DeviceCallback(pl.Callback):\n    def on_batch_start(self, trainer, pl_module):\n        assert next(pl_module.parameters()).device.type == \"cuda\"\n\nclass LoggingCallback(pl.Callback):\n    def on_validation_end(self, trainer, pl_module):\n        logger.info(\"***** Validation results *****\")\n        if pl_module.is_logger():\n            metrics = trainer.callback_metrics\n            # Log results\n            for key in sorted(metrics):\n                if key not in [\"log\", \"progress_bar\"]:\n                    logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n    def on_test_end(self, trainer, pl_module):\n        logger.info(\"***** Validation results *****\")\n        if pl_module.is_logger():\n            metrics = trainer.callback_metrics\n            # Log results\n            for key in sorted(metrics):\n                if key not in [\"log\", \"progress_bar\"]:\n                    logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n\n    def on_test_end(self, trainer, pl_module):\n        logger.info(\"***** Test results *****\")\n        if pl_module.is_logger():\n            metrics = trainer.callback_metrics\n            # Log and save results to file\n            output_test_results_file = os.path.join(pl_module.config.output_dir, \"test_results.txt\")\n            with open(output_test_results_file, \"w\") as writer:\n                for key in sorted(metrics):\n                    if key not in [\"log\", \"progress_bar\"]:\n                        logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n                        writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))","metadata":{"id":"BGVTpK7g6oHl","execution":{"iopub.status.busy":"2023-08-26T20:25:44.144361Z","iopub.execute_input":"2023-08-26T20:25:44.146652Z","iopub.status.idle":"2023-08-26T20:25:44.162742Z","shell.execute_reply.started":"2023-08-26T20:25:44.146614Z","shell.execute_reply":"2023-08-26T20:25:44.161893Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"checkpoint_callback = pl.callbacks.ModelCheckpoint(\n    dirpath = config.output_dir, monitor=\"validation_f1_step\", mode=\"max\", save_top_k=1\n)\ntrain_params = dict(\n    devices=config.n_gpu,\n    strategy=\"auto\",\n    accumulate_grad_batches=config.gradient_accumulation_steps,\n    accelerator=\"gpu\",\n    max_epochs=config.num_train_epochs,\n    precision= 32,\n    gradient_clip_val=config.max_grad_norm,\n    callbacks=[LoggingCallback(),checkpoint_callback,DeviceCallback()],\n)","metadata":{"id":"U9tLgD2O6oHl","execution":{"iopub.status.busy":"2023-08-26T20:25:44.167623Z","iopub.execute_input":"2023-08-26T20:25:44.170690Z","iopub.status.idle":"2023-08-26T20:25:44.191114Z","shell.execute_reply.started":"2023-08-26T20:25:44.170653Z","shell.execute_reply":"2023-08-26T20:25:44.189907Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"feB5OEdeoV91"}},{"cell_type":"markdown","source":"Coming to the most interesting part - the model architecture! We'll create a class named **Model**, inherited from **torch.nn.Module**.<br><br>\n\n### Flow\n- We initialize our pretrained T5 model with a Conditional Generation Head.\n- Pass in the src & tgt, input_ids & attention_mask.\n- The model returns the decoder generated output ids (predicted labels in textual format), which we need to decode further using the tokenizer.","metadata":{"id":"HjqZhSB8C0Qk"}},{"cell_type":"code","source":"import numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-08-26T20:25:44.195320Z","iopub.execute_input":"2023-08-26T20:25:44.197574Z","iopub.status.idle":"2023-08-26T20:25:44.203970Z","shell.execute_reply.started":"2023-08-26T20:25:44.197538Z","shell.execute_reply":"2023-08-26T20:25:44.202978Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class T5FineTuner(pl.LightningModule):\n    def __init__(self, config):\n        super().__init__()\n        self.config = config\n        self.model = T5ForConditionalGeneration.from_pretrained(config.model_name_or_path)\n        self.tokenizer = T5Tokenizer.from_pretrained(config.model_name_or_path)\n        self.training_step_outputs = []\n        self.validation_step_outputs = []\n        self.test_step_outputs = []\n        self.outputsf1 = []\n        self.targetsf1 = []\n\n    def is_logger(self):\n        return self.trainer.global_rank  <= 0\n\n    def forward(\n        self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, labels=None\n        ):\n        return self.model(\n            input_ids,\n            attention_mask=attention_mask,\n            decoder_input_ids=decoder_input_ids,\n            decoder_attention_mask=decoder_attention_mask,\n            labels=labels,\n            )\n\n    def _step(self, batch):\n        lm_labels = batch[\"target_ids\"]\n        lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n        outputs = self(\n        input_ids=batch[\"source_ids\"],\n        attention_mask=batch[\"source_mask\"],\n        labels=lm_labels,\n        decoder_attention_mask=batch['target_mask']\n        )\n\n        loss = outputs[0]\n        return loss\n\n    def training_step(self, batch, batch_idx):\n        loss = self._step(batch)\n        self.log(\"train/loss\", loss)\n        self.training_step_outputs.append(loss)\n        return loss\n\n    def on_train_epoch_end(self):\n        \n        epoch_average = torch.stack(self.training_step_outputs).mean()\n        self.log(\"training_epoch_average\", epoch_average, sync_dist=True, prog_bar=True, logger=True, on_epoch=True)\n        self.training_step_outputs.clear()  # free memory\n\n    def test_step(self, batch, batch_idx):\n        loss = self._step(batch)\n        self.test_step_outputs.append(loss)\n        return loss\n\n    def on_test_epoch_end(self):\n        epoch_average = torch.stack(self.test_step_outputs).mean()\n        self.log(\"test_epoch_average\", epoch_average,  sync_dist=True, prog_bar=True, logger=True, on_epoch=True)\n        self.test_step_outputs.clear()  # free memory\n\n    def validation_step(self, batch, batch_idx):\n        loss = self._step(batch)\n        self.validation_step_outputs.append(loss)\n        \n        outs = self.model.generate(input_ids=batch['source_ids'],\n                              attention_mask=batch['source_mask'],\n                              max_length=2)\n\n        target = batch[\"target_ids\"]\n        self.outputsf1.append(outs.detach().tolist())\n        self.targetsf1.append(target.detach().tolist())\n        return loss\n\n    def on_validation_epoch_end(self):\n        epoch_average = torch.stack(self.validation_step_outputs).mean()\n        #target_binary = mlb.fit_transform(self.targetsf1)\n        #output_binary = mlb.transform(self.outputsf1)\n        print(10*\"*\")\n        print(len(self.outputsf1))\n        print(len(self.outputsf1[0]))\n        print(len(self.outputsf1[0][0]))\n        print(10*\"-\")\n        print(len(self.targetsf1))\n        print(len(self.targetsf1[0]))\n        print(len(self.targetsf1[0][0]))\n        print(10*\"#\")\n        \n        #out_flat = [pair[0] for sublist in self.outputsf1 for pair in sublist]\n        #target_flat = [pair[0] for sublist in self.targetsf1 for pair in sublist]\n        targets = [ids[0] for batch in self.targetsf1 for ids in batch]\n        outputs = [ids[0] for batch in self.outputsf1 for ids in batch]\n        \n        f1 = f1_score(torch.tensor(targets,outputs,average='macro')\n        self.log(\"validation_f1_step\",f1 ,  sync_dist=True, prog_bar=True, logger=True, on_epoch=True)\n        self.log(\"validation_epoch_average\", epoch_average, sync_dist=True, prog_bar=True, logger=True, on_epoch=True)\n        self.validation_step_outputs.clear()\n        self.targetsf1.clear()\n        self.outputsf1.clear()\n        # free memory\n\n    def configure_optimizers(self):\n        \"Prepare optimizer and schedule (linear warmup and decay)\"\n\n        model = self.model\n        no_decay = [\"bias\", \"LayerNorm.weight\"]\n\n        optimizer_grouped_parameters = [\n        {\n            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n            \"weight_decay\": self.config.weight_decay,\n        },\n        {\n            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n            \"weight_decay\": 0.0,\n        },\n        ]\n        optimizer = AdamW(optimizer_grouped_parameters, lr=self.config.learning_rate, eps=self.config.adam_epsilon)\n        scheduler = get_linear_schedule_with_warmup(\n        optimizer, num_warmup_steps=self.config.warmup_steps, num_training_steps=self.trainer.estimated_stepping_batches)\n        self.lr_scheduler = scheduler\n        scheduler = {\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}\n        return [optimizer],[scheduler]\n\n    def get_tqdm_dict(self):\n        tqdm_dict = {\"loss\": \"{:.3f}\".format(self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n        return tqdm_dict\n\n    def train_dataloader(self):\n        train_dataset = get_dataset(config=self.config, tokenizer=self.tokenizer, part=\"train\")\n        return DataLoader(train_dataset, batch_size=self.config.train_batch_size, drop_last=True, shuffle=True,num_workers=2,pin_memory=True)\n    def val_dataloader(self):\n        val_dataset = get_dataset(config=self.config,tokenizer=self.tokenizer, part=\"val\")\n        return DataLoader(val_dataset, batch_size=self.config.eval_batch_size, num_workers=2,pin_memory=True)\n    def test_dataloader(self):\n        val_dataset = get_dataset(config=self.config,tokenizer=self.tokenizer, part=\"test\")\n        return DataLoader(val_dataset, batch_size=self.config.eval_batch_size, num_workers=2,pin_memory=True)","metadata":{"id":"d1xG8CCdlgge","execution":{"iopub.status.busy":"2023-08-26T20:25:44.211772Z","iopub.execute_input":"2023-08-26T20:25:44.214013Z","iopub.status.idle":"2023-08-26T20:25:44.255580Z","shell.execute_reply.started":"2023-08-26T20:25:44.213979Z","shell.execute_reply":"2023-08-26T20:25:44.254493Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model = T5FineTuner(config)","metadata":{"id":"jiypz6jrG9bl","outputId":"d16d6835-314f-4c02-842f-0962de051474","execution":{"iopub.status.busy":"2023-08-26T20:25:44.260258Z","iopub.execute_input":"2023-08-26T20:25:44.262868Z","iopub.status.idle":"2023-08-26T20:26:05.482775Z","shell.execute_reply.started":"2023-08-26T20:25:44.262833Z","shell.execute_reply":"2023-08-26T20:26:05.481743Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/699 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad35ea7ecb8e404fbe1640af51c7fe8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/1.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfbabc975220475683edf245d4e1cc25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53e2e71edf134416aba6f0d15533c27c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading spiece.model:   0%|          | 0.00/2.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d352dd4de3c5485e9f951705edfa3f93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"faf5bc7e4b794d33b42a3a1a6353ab41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/2.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"048c5996edb144edbdff40769f6af8e3"}},"metadata":{}}]},{"cell_type":"code","source":"trainer = pl.Trainer(**train_params)","metadata":{"id":"mlsnd6mu6oHn","outputId":"dfe6f12c-9dda-483b-b4e8-5f8056df362b","execution":{"iopub.status.busy":"2023-08-26T20:26:05.488309Z","iopub.execute_input":"2023-08-26T20:26:05.491216Z","iopub.status.idle":"2023-08-26T20:26:06.428603Z","shell.execute_reply.started":"2023-08-26T20:26:05.491173Z","shell.execute_reply":"2023-08-26T20:26:06.427737Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"INFO: GPU available: True (cuda), used: True\nINFO: TPU available: False, using: 0 TPU cores\nINFO: IPU available: False, using: 0 IPUs\nINFO: HPU available: False, using: 0 HPUs\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.fit(model)","metadata":{"id":"iZ59dtmH6oHo","outputId":"b6530313-d689-4dc7-829e-24b7c9c333e6","execution":{"iopub.status.busy":"2023-08-26T20:26:06.433071Z","iopub.execute_input":"2023-08-26T20:26:06.435325Z","iopub.status.idle":"2023-08-26T20:27:28.416856Z","shell.execute_reply.started":"2023-08-26T20:26:06.435268Z","shell.execute_reply":"2023-08-26T20:27:28.412329Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"INFO: ----------------------------------------------------------------------------------------------------\ndistributed_backend=nccl\nAll distributed processes registered. Starting with 2 processes\n----------------------------------------------------------------------------------------------------\n\nINFO: Loading `train_dataloader` to estimate number of stepping batches.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2392: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/cuda/jit_utils.cpp:1442.)\n  next_tokens.tile(eos_token_id_tensor.shape[0], 1).ne(eos_token_id_tensor.unsqueeze(1)).prod(dim=0)\n","output_type":"stream"},{"name":"stdout","text":"**********\n2\n10\n2**********\n----------\n2\n10\n\n2\n2##########\n\n10\n2\n----------\n2\n10\n2\n##########\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cef226d72fe461993bd468e9eee451c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3503f77bdbe94ee9878fd23be734c253"}},"metadata":{}},{"name":"stdout","text":"**********\n127\n10\n2\n----------\n127\n10\n2\n##########\n**********\n127\n10\n2\n----------\n127\n10\n2\n##########\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 trainer.fit(model)                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m532\u001b[0m in \u001b[92mfit\u001b[0m          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 529 \u001b[0m\u001b[2m│   │   \u001b[0mmodel = _maybe_unwrap_optimized(model)                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 530 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.strategy._lightning_module = model                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 531 \u001b[0m\u001b[2m│   │   \u001b[0m_verify_strategy_supports_compile(model, \u001b[96mself\u001b[0m.strategy)                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 532 \u001b[2m│   │   \u001b[0mcall._call_and_handle_interrupt(                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 533 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m, \u001b[96mself\u001b[0m._fit_impl, model, train_dataloaders, val_dataloaders, datamodule,  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 534 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 535 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/\u001b[0m\u001b[1;33mcall.py\u001b[0m:\u001b[94m42\u001b[0m in                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[92m_call_and_handle_interrupt\u001b[0m                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 39 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 40 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mtry\u001b[0m:                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 41 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m trainer.strategy.launcher \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 42 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer,    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 43 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m trainer_fn(*args, **kwargs)                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 44 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 45 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mexcept\u001b[0m _TunerExitException:                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/\u001b[0m\u001b[1;33mmultiprocessing.p\u001b[0m \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m126\u001b[0m in \u001b[92mlaunch\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m123 \u001b[0m\u001b[2m│   │   │   \u001b[0mjoin=\u001b[94mFalse\u001b[0m,  \u001b[2m# we will join ourselves to get the process references\u001b[0m            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m124 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m125 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.procs = process_context.processes                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m126 \u001b[2m│   │   \u001b[0m\u001b[94mwhile\u001b[0m \u001b[95mnot\u001b[0m process_context.join():                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m127 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mpass\u001b[0m                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m128 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m129 \u001b[0m\u001b[2m│   │   \u001b[0mworker_output = return_queue.get()                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/\u001b[0m\u001b[1;33mspawn.py\u001b[0m:\u001b[94m160\u001b[0m in \u001b[92mjoin\u001b[0m               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m│   │   \u001b[0moriginal_trace = \u001b[96mself\u001b[0m.error_queues[error_index].get()                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m158 \u001b[0m\u001b[2m│   │   \u001b[0mmsg = \u001b[33m\"\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m-- Process \u001b[0m\u001b[33m%d\u001b[0m\u001b[33m terminated with the following error:\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m\"\u001b[0m % error_index     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m159 \u001b[0m\u001b[2m│   │   \u001b[0mmsg += original_trace                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m160 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m ProcessRaisedException(msg, error_index, failed_process.pid)                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m161 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m162 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92mSpawnContext\u001b[0m(ProcessContext):                                                        \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mProcessRaisedException: \u001b[0m\n\n-- Process \u001b[1;36m1\u001b[0m terminated with the following error:\nTraceback \u001b[1m(\u001b[0mmost recent call last\u001b[1m)\u001b[0m:\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\"\u001b[0m, line \u001b[1;36m69\u001b[0m, in _wrap\n    \u001b[1;35mfn\u001b[0m\u001b[1m(\u001b[0mi, *args\u001b[1m)\u001b[0m\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py\"\u001b[0m, line \n\u001b[1;36m149\u001b[0m, in _wrapping_function\n    results = \u001b[1;35mfunction\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\"\u001b[0m, line \u001b[1;36m571\u001b[0m, in _fit_impl\n    \u001b[1;35mself._run\u001b[0m\u001b[1m(\u001b[0mmodel, \u001b[33mckpt_path\u001b[0m=\u001b[35mckpt_path\u001b[0m\u001b[1m)\u001b[0m\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\"\u001b[0m, line \u001b[1;36m980\u001b[0m, in _run\n    results = \u001b[1;35mself._run_stage\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\"\u001b[0m, line \u001b[1;36m1023\u001b[0m, in _run_stage\n    \u001b[1;35mself.fit_loop.run\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py\"\u001b[0m, line \u001b[1;36m202\u001b[0m, in run\n    \u001b[1;35mself.advance\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py\"\u001b[0m, line \u001b[1;36m355\u001b[0m, in advance\n    \u001b[1;35mself.epoch_loop.run\u001b[0m\u001b[1m(\u001b[0mself._data_fetcher\u001b[1m)\u001b[0m\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py\"\u001b[0m, line \u001b[1;36m134\u001b[0m, in run\n    \u001b[1;35mself.on_advance_end\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py\"\u001b[0m, line \u001b[1;36m249\u001b[0m, in \non_advance_end\n    \u001b[1;35mself.val_loop.run\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py\"\u001b[0m, line \u001b[1;36m181\u001b[0m, in _decorator\n    return \u001b[1;35mloop_run\u001b[0m\u001b[1m(\u001b[0mself, *args, **kwargs\u001b[1m)\u001b[0m\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\"\u001b[0m, line \u001b[1;36m122\u001b[0m, in run\n    return \u001b[1;35mself.on_run_end\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\"\u001b[0m, line \u001b[1;36m244\u001b[0m, in \non_run_end\n    \u001b[1;35mself._on_evaluation_epoch_end\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\"\u001b[0m, line \u001b[1;36m326\u001b[0m, in \n_on_evaluation_epoch_end\n    \u001b[1;35mcall._call_lightning_module_hook\u001b[0m\u001b[1m(\u001b[0mtrainer, hook_name\u001b[1m)\u001b[0m\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\"\u001b[0m, line \u001b[1;36m145\u001b[0m, in \n_call_lightning_module_hook\n    output = \u001b[1;35mfn\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m\n  File \u001b[32m\"/tmp/ipykernel_28/1964470551.py\"\u001b[0m, line \u001b[1;36m93\u001b[0m, in on_validation_epoch_end\n    f1 = \u001b[1;35mf1_score\u001b[0m\u001b[1m(\u001b[0m\u001b[1;35mtorch.tensor\u001b[0m\u001b[1m(\u001b[0mself.targetsf1\u001b[1m)\u001b[0m\u001b[1m[\u001b[0m\u001b[33m...\u001b[0m ,\u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1;35m.flatten\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mtorch.tensor\u001b[0m\u001b[1m(\u001b[0mself.outputsf1\u001b[1m)\u001b[0m\u001b[1m[\u001b[0m\u001b[33m...\u001b[0m \n,\u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1;35m.flatten\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m,\u001b[33maverage\u001b[0m=\u001b[32m'macro'\u001b[0m\u001b[1m)\u001b[0m\nValueError: expected sequence of length \u001b[1;36m10\u001b[0m at dim \u001b[1;36m1\u001b[0m \u001b[1m(\u001b[0mgot \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m\n\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 trainer.fit(model)                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">532</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fit</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 529 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>model = _maybe_unwrap_optimized(model)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 530 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.strategy._lightning_module = model                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 531 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>_verify_strategy_supports_compile(model, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.strategy)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 532 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>call._call_and_handle_interrupt(                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 533 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._fit_impl, model, train_dataloaders, val_dataloaders, datamodule,  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 534 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 535 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">call.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">42</span> in                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_and_handle_interrupt</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 39 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 40 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 41 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> trainer.strategy.launcher <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 42 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer,    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 43 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> trainer_fn(*args, **kwargs)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 44 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 45 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> _TunerExitException:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">multiprocessing.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">126</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">launch</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">123 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>join=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>,  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># we will join ourselves to get the process references</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">124 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">125 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.procs = process_context.processes                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>126 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">while</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> process_context.join():                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">127 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">pass</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">129 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>worker_output = return_queue.get()                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">spawn.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">160</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">join</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">157 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>original_trace = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.error_queues[error_index].get()                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">158 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>msg = <span style=\"color: #808000; text-decoration-color: #808000\">\"\\n\\n-- Process %d terminated with the following error:\\n\"</span> % error_index     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">159 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>msg += original_trace                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>160 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> ProcessRaisedException(msg, error_index, failed_process.pid)                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">161 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">162 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">SpawnContext</span>(ProcessContext):                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ProcessRaisedException: </span>\n\n-- Process <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> terminated with the following error:\nTraceback <span style=\"font-weight: bold\">(</span>most recent call last<span style=\"font-weight: bold\">)</span>:\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">69</span>, in _wrap\n    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">fn</span><span style=\"font-weight: bold\">(</span>i, *args<span style=\"font-weight: bold\">)</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py\"</span>, line \n<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">149</span>, in _wrapping_function\n    results = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">function</span><span style=\"font-weight: bold\">(</span>*args, **kwargs<span style=\"font-weight: bold\">)</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">571</span>, in _fit_impl\n    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self._run</span><span style=\"font-weight: bold\">(</span>model, <span style=\"color: #808000; text-decoration-color: #808000\">ckpt_path</span>=<span style=\"color: #800080; text-decoration-color: #800080\">ckpt_path</span><span style=\"font-weight: bold\">)</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">980</span>, in _run\n    results = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self._run_stage</span><span style=\"font-weight: bold\">()</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1023</span>, in _run_stage\n    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.fit_loop.run</span><span style=\"font-weight: bold\">()</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">202</span>, in run\n    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.advance</span><span style=\"font-weight: bold\">()</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">355</span>, in advance\n    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.epoch_loop.run</span><span style=\"font-weight: bold\">(</span>self._data_fetcher<span style=\"font-weight: bold\">)</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">134</span>, in run\n    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.on_advance_end</span><span style=\"font-weight: bold\">()</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">249</span>, in \non_advance_end\n    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.val_loop.run</span><span style=\"font-weight: bold\">()</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">181</span>, in _decorator\n    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">loop_run</span><span style=\"font-weight: bold\">(</span>self, *args, **kwargs<span style=\"font-weight: bold\">)</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">122</span>, in run\n    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.on_run_end</span><span style=\"font-weight: bold\">()</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">244</span>, in \non_run_end\n    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self._on_evaluation_epoch_end</span><span style=\"font-weight: bold\">()</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">326</span>, in \n_on_evaluation_epoch_end\n    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">call._call_lightning_module_hook</span><span style=\"font-weight: bold\">(</span>trainer, hook_name<span style=\"font-weight: bold\">)</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">145</span>, in \n_call_lightning_module_hook\n    output = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">fn</span><span style=\"font-weight: bold\">(</span>*args, **kwargs<span style=\"font-weight: bold\">)</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/tmp/ipykernel_28/1964470551.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">93</span>, in on_validation_epoch_end\n    f1 = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">f1_score</span><span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.tensor</span><span style=\"font-weight: bold\">(</span>self.targetsf1<span style=\"font-weight: bold\">)[</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span> ,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.flatten</span><span style=\"font-weight: bold\">()</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.tensor</span><span style=\"font-weight: bold\">(</span>self.outputsf1<span style=\"font-weight: bold\">)[</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span> \n,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.flatten</span><span style=\"font-weight: bold\">()</span>,<span style=\"color: #808000; text-decoration-color: #808000\">average</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'macro'</span><span style=\"font-weight: bold\">)</span>\nValueError: expected sequence of length <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> at dim <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"font-weight: bold\">(</span>got <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>\n\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"help(Dataset)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T20:27:28.417921Z","iopub.status.idle":"2023-08-26T20:27:28.418440Z","shell.execute_reply.started":"2023-08-26T20:27:28.418166Z","shell.execute_reply":"2023-08-26T20:27:28.418192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = T5Tokenizer.from_pretrained(config.model_name_or_path)","metadata":{"id":"QEVJPRXWgnZw","execution":{"iopub.status.busy":"2023-08-26T20:27:28.420309Z","iopub.status.idle":"2023-08-26T20:27:28.420792Z","shell.execute_reply.started":"2023-08-26T20:27:28.420539Z","shell.execute_reply":"2023-08-26T20:27:28.420562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model = T5FineTuner.load_from_checkpoint(\"/content/logs/epoch=9-step=80.ckpt\",config=config)","metadata":{"id":"ihFL9T55h4ss","execution":{"iopub.status.busy":"2023-08-26T20:27:28.421891Z","iopub.status.idle":"2023-08-26T20:27:28.422311Z","shell.execute_reply.started":"2023-08-26T20:27:28.422086Z","shell.execute_reply":"2023-08-26T20:27:28.422108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.cuda()\noutputs = []\ntargets = []\nfor batch in tqdm(loader):\n    outs = model.model.generate(input_ids=batch['source_ids'].cuda(),\n                              attention_mask=batch['source_mask'].cuda(),\n                              max_length=2)\n\n    dec = [tokenizer.decode(ids[ids > 1 ]) for ids in outs]\n    target = [tokenizer.decode((ids[ids > 1 ])) for ids in batch[\"target_ids\"]]\n\n    outputs.extend(dec)\n    targets.extend(target)","metadata":{"id":"MEa00VKtVQq-","outputId":"1df2ef83-00d2-4fd1-ddc5-8cfe603f9a7f","execution":{"iopub.status.busy":"2023-08-26T20:27:28.424633Z","iopub.status.idle":"2023-08-26T20:27:28.425231Z","shell.execute_reply.started":"2023-08-26T20:27:28.424953Z","shell.execute_reply":"2023-08-26T20:27:28.424982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(metrics.classification_report(targets, outputs))","metadata":{"id":"hCOjxCSbVSY2","outputId":"6f3cc0be-79dc-4cbb-8fba-f1bcfd7df838","execution":{"iopub.status.busy":"2023-08-26T20:27:28.432339Z","iopub.status.idle":"2023-08-26T20:27:28.432824Z","shell.execute_reply.started":"2023-08-26T20:27:28.432567Z","shell.execute_reply":"2023-08-26T20:27:28.432589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import textwrap","metadata":{"id":"3gqbs7XaECCm","execution":{"iopub.status.busy":"2023-08-26T20:27:28.433878Z","iopub.status.idle":"2023-08-26T20:27:28.434369Z","shell.execute_reply.started":"2023-08-26T20:27:28.434100Z","shell.execute_reply":"2023-08-26T20:27:28.434125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(32):\n    lines = textwrap.wrap(\"Review:\\n%s\\n\" % texts[i], width=100)\n    print(\"\\n\".join(lines))\n    print(\"\\nActual sentiment: %s\" % targets[i])\n    print(\"Predicted sentiment: %s\" % dec[i])\n    print(\"=====================================================================\\n\")","metadata":{"id":"7sw2flRKD-Ee","execution":{"iopub.status.busy":"2023-08-26T20:27:28.435519Z","iopub.status.idle":"2023-08-26T20:27:28.436102Z","shell.execute_reply.started":"2023-08-26T20:27:28.435863Z","shell.execute_reply":"2023-08-26T20:27:28.435886Z"},"trusted":true},"execution_count":null,"outputs":[]}]}