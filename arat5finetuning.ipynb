{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2980eb2f",
   "metadata": {
    "id": "buleZD1j2kLm",
    "papermill": {
     "duration": 0.007669,
     "end_time": "2023-08-25T18:29:39.806528",
     "exception": false,
     "start_time": "2023-08-25T18:29:39.798859",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### [T5](https://github.com/google-research/text-to-text-transfer-transformer)\n",
    "- **Text-To-Text Transfer Transformer**\n",
    "- A unified framework that converts every language problem into a text-to-text format.\n",
    "- Achieves state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more.\n",
    "\n",
    "### Multi Class vs Multi Label Classification\n",
    "- **Multi Class** - There are multiple categories but each instance is assigned only one, therefore such problems are known as multi-class classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80df0e52",
   "metadata": {
    "id": "vr-nvX_HT4_K",
    "papermill": {
     "duration": 0.005177,
     "end_time": "2023-08-25T18:29:39.817441",
     "exception": false,
     "start_time": "2023-08-25T18:29:39.812264",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772bb55f",
   "metadata": {
    "id": "GqOpA5x73pYs",
    "papermill": {
     "duration": 0.005078,
     "end_time": "2023-08-25T18:29:39.828100",
     "exception": false,
     "start_time": "2023-08-25T18:29:39.823022",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The entire code is written using **PyTorch**.<br>\n",
    "We'll be using the **transformers** library by [huggingface](https://github.com/huggingface/transformers) as they provide wrappers for multiple Transformer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c358382",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T18:29:39.840885Z",
     "iopub.status.busy": "2023-08-25T18:29:39.840458Z",
     "iopub.status.idle": "2023-08-25T18:30:26.784305Z",
     "shell.execute_reply": "2023-08-25T18:30:26.782954Z"
    },
    "id": "9J7Ws11-9PqG",
    "papermill": {
     "duration": 46.953668,
     "end_time": "2023-08-25T18:30:26.787084",
     "exception": false,
     "start_time": "2023-08-25T18:29:39.833416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.2)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\r\n",
      "Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (2.0.4)\r\n",
      "Collecting pytorch-lightning\r\n",
      "  Downloading pytorch_lightning-2.0.7-py3-none-any.whl (724 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m725.0/725.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (1.23.5)\r\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (2.0.0+cpu)\r\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (4.65.0)\r\n",
      "Requirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (6.0)\r\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (2023.6.0)\r\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (1.0.0)\r\n",
      "Requirement already satisfied: packaging>=17.1 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (21.3)\r\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (4.6.3)\r\n",
      "Requirement already satisfied: lightning-utilities>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (0.9.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.31.0)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.4)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=17.1->pytorch-lightning) (3.0.9)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (3.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (3.1.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (3.1.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.3)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (2.1.3)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2023.5.7)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->pytorch-lightning) (1.3.0)\r\n",
      "Installing collected packages: pytorch-lightning\r\n",
      "  Attempting uninstall: pytorch-lightning\r\n",
      "    Found existing installation: pytorch-lightning 2.0.4\r\n",
      "    Uninstalling pytorch-lightning-2.0.4:\r\n",
      "      Successfully uninstalled pytorch-lightning-2.0.4\r\n",
      "Successfully installed pytorch-lightning-2.0.7\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.1.99)\r\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\r\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (9.0.0)\r\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (1.5.3)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.65.0)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.2.0)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\r\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.6.0)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.16.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\r\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.6.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install pytorch-lightning --upgrade\n",
    "!pip install sentencepiece\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd89f4a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T18:30:26.804271Z",
     "iopub.status.busy": "2023-08-25T18:30:26.803841Z",
     "iopub.status.idle": "2023-08-25T18:30:26.812693Z",
     "shell.execute_reply": "2023-08-25T18:30:26.811772Z"
    },
    "id": "61f6obyD_Kud",
    "outputId": "63cd297c-7f38-4c70-d1fa-1b644585edc1",
    "papermill": {
     "duration": 0.020138,
     "end_time": "2023-08-25T18:30:26.814774",
     "exception": false,
     "start_time": "2023-08-25T18:30:26.794636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rom google.colab import files\\n\\nfiles.upload()\\n! mkdir ~/.kaggle\\n! cp kaggle.json ~/.kaggle/\\n! chmod 600 ~/.kaggle/kaggle.json\\n! kaggle datasets download -d sifalklioui/hatespeechdza\\n!mkdir data\\n!unzip hatespeechdza.zip -d ./data'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''rom google.colab import files\n",
    "\n",
    "files.upload()\n",
    "! mkdir ~/.kaggle\n",
    "! cp kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json\n",
    "! kaggle datasets download -d sifalklioui/hatespeechdza\n",
    "!mkdir data\n",
    "!unzip hatespeechdza.zip -d ./data'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d1efba6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T18:30:26.831451Z",
     "iopub.status.busy": "2023-08-25T18:30:26.831075Z",
     "iopub.status.idle": "2023-08-25T18:30:43.682308Z",
     "shell.execute_reply": "2023-08-25T18:30:43.681198Z"
    },
    "id": "07GPLpCt_AjQ",
    "papermill": {
     "duration": 16.862948,
     "end_time": "2023-08-25T18:30:43.685221",
     "exception": false,
     "start_time": "2023-08-25T18:30:26.822273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "import random\n",
    "import torch\n",
    "import logging\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataclasses import dataclass\n",
    "import pytorch_lightning as pl\n",
    "from torch.optim import AdamW\n",
    "from sklearn import metrics\n",
    "\n",
    "from transformers import (\n",
    "    T5Tokenizer,\n",
    "    T5Model,\n",
    "    T5ForConditionalGeneration,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84558391",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T18:30:43.704082Z",
     "iopub.status.busy": "2023-08-25T18:30:43.703618Z",
     "iopub.status.idle": "2023-08-25T18:30:43.711560Z",
     "shell.execute_reply": "2023-08-25T18:30:43.710715Z"
    },
    "id": "281L6wVJ6oHj",
    "papermill": {
     "duration": 0.019122,
     "end_time": "2023-08-25T18:30:43.713621",
     "exception": false,
     "start_time": "2023-08-25T18:30:43.694499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    seed = 203\n",
    "    data_folder = \"../input/hatespeechdza\"\n",
    "    output_dir = './logs'\n",
    "    model_name_or_path = 'UBC-NLP/AraT5v2-base-1024'\n",
    "    src_max_length = 45\n",
    "    tgt_max_length = 2\n",
    "    add_special_tokens = True\n",
    "    truncation = True\n",
    "    return_tensors = 'pt'\n",
    "    padding = \"max_length\"\n",
    "    weight_decay=0.0\n",
    "    adam_epsilon=1e-8\n",
    "    warmup_steps=0\n",
    "    train_batch_size=64\n",
    "    eval_batch_size=64\n",
    "    num_train_epochs=10\n",
    "    gradient_accumulation_steps=16\n",
    "    n_gpu=1\n",
    "    fp_16= False, # if you want to enable 16-bit training then install apex and set this to true\n",
    "    max_grad_norm=1.0 # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n",
    "    learning_rate= float(3e-4)\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22f2bc51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T18:30:43.732158Z",
     "iopub.status.busy": "2023-08-25T18:30:43.731124Z",
     "iopub.status.idle": "2023-08-25T18:30:43.741966Z",
     "shell.execute_reply": "2023-08-25T18:30:43.740822Z"
    },
    "id": "8_WV69kk6oHk",
    "papermill": {
     "duration": 0.022698,
     "end_time": "2023-08-25T18:30:43.744511",
     "exception": false,
     "start_time": "2023-08-25T18:30:43.721813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6451324f",
   "metadata": {
    "id": "e1AhmXnXByg5",
    "papermill": {
     "duration": 0.007521,
     "end_time": "2023-08-25T18:30:43.760023",
     "exception": false,
     "start_time": "2023-08-25T18:30:43.752502",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16de4f5",
   "metadata": {
    "id": "cwrzxPV8B1Es",
    "papermill": {
     "duration": 0.007581,
     "end_time": "2023-08-25T18:30:43.775795",
     "exception": false,
     "start_time": "2023-08-25T18:30:43.768214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, we'll create a custom Dataset class inherited from the PyTorch Dataset class. We'll be using the **T5 tokenizer** that returns **input_ids** and **attention_mask**.<br><br>\n",
    "The custom Dataset class will return a dict containing - <br>\n",
    "\n",
    "- src_input_ids\n",
    "- src_attention_mask\n",
    "- tgt_input_ids'\n",
    "-tgt_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a57f07c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T18:30:43.793067Z",
     "iopub.status.busy": "2023-08-25T18:30:43.792628Z",
     "iopub.status.idle": "2023-08-25T18:30:44.202263Z",
     "shell.execute_reply": "2023-08-25T18:30:44.201048Z"
    },
    "id": "w0D46GkV6oHl",
    "papermill": {
     "duration": 0.421466,
     "end_time": "2023-08-25T18:30:44.205033",
     "exception": false,
     "start_time": "2023-08-25T18:30:43.783567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset,load_dataset\n",
    "\n",
    "class HateDetect():\n",
    "    def __init__(self,config,tokenizer, part):\n",
    "\n",
    "        self.config = config\n",
    "        self.part = part\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "\n",
    "        data_paths = {\n",
    "            'train': config.data_folder + \"/dataset_prep_train.csv\",\n",
    "            'test': config.data_folder + \"/dataset_prep_test.csv\",\n",
    "            'val': config.data_folder + \"/dataset_prep_val.csv\"\n",
    "        }\n",
    "        path = data_paths.get(self.part,None)\n",
    "        if path is not None:\n",
    "            df = pd.read_csv(path)\n",
    "            df['label'].replace({0:\"normal\",1:\"hate\"}, inplace = True)\n",
    "            self.data = Dataset.from_pandas(df ,split=self.part)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid value for self.part\")\n",
    "\n",
    "\n",
    "        self.dataset_scr,self.dataset_tgt = self.tokenize()\n",
    "\n",
    "        # create funtion to tokenize data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "\n",
    "        source_ids = self.dataset_scr[\"input_ids\"][idx].squeeze()\n",
    "        target_ids = self.dataset_tgt[\"input_ids\"][idx].squeeze()\n",
    "\n",
    "        src_mask    = self.dataset_scr[\"attention_mask\"][idx].squeeze()\n",
    "        target_mask = self.dataset_tgt[\"attention_mask\"][idx].squeeze()\n",
    "\n",
    "        return {\"source_ids\": source_ids,\n",
    "                \"source_mask\": src_mask,\n",
    "                \"target_ids\": target_ids,\n",
    "                \"target_mask\": target_mask}\n",
    "\n",
    "\n",
    "    def tokenize(self):\n",
    "\n",
    "        tokenizer_params = {\n",
    "            \"src\": {\n",
    "                \"max_length\": self.config.src_max_length,\n",
    "                \"add_special_tokens\": self.config.add_special_tokens,\n",
    "                \"truncation\": self.config.truncation,\n",
    "                \"return_tensors\": self.config.return_tensors,\n",
    "                \"padding\": self.config.padding\n",
    "            },\n",
    "            \"tgt\": {\n",
    "                \"max_length\": self.config.tgt_max_length,\n",
    "                \"add_special_tokens\": self.config.add_special_tokens,\n",
    "                \"truncation\": self.config.truncation,\n",
    "                \"return_tensors\": self.config.return_tensors,\n",
    "                \"padding\": self.config.padding\n",
    "            }\n",
    "        }\n",
    "        dataset_scr = self.tokenizer.batch_encode_plus(self.data['text'], **tokenizer_params[\"src\"])\n",
    "        dataset_tgt = self.tokenizer.batch_encode_plus(self.data['label'], **tokenizer_params[\"tgt\"])\n",
    "        return dataset_scr,dataset_tgt\n",
    "\n",
    "def get_dataset(config,tokenizer,part):\n",
    "    return HateDetect(config,tokenizer,part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "483d3073",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T18:30:44.224693Z",
     "iopub.status.busy": "2023-08-25T18:30:44.223503Z",
     "iopub.status.idle": "2023-08-25T18:30:44.233244Z",
     "shell.execute_reply": "2023-08-25T18:30:44.232369Z"
    },
    "id": "BGVTpK7g6oHl",
    "papermill": {
     "duration": 0.022478,
     "end_time": "2023-08-25T18:30:44.235562",
     "exception": false,
     "start_time": "2023-08-25T18:30:44.213084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class DeviceCallback(pl.Callback):\n",
    "    def on_batch_start(self, trainer, pl_module):\n",
    "        assert next(pl_module.parameters()).device.type == \"cuda\"\n",
    "\n",
    "class LoggingCallback(pl.Callback):\n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        logger.info(\"***** Validation results *****\")\n",
    "        if pl_module.is_logger():\n",
    "            metrics = trainer.callback_metrics\n",
    "            # Log results\n",
    "            for key in sorted(metrics):\n",
    "                if key not in [\"log\", \"progress_bar\"]:\n",
    "                    logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "\n",
    "    def on_test_end(self, trainer, pl_module):\n",
    "        logger.info(\"***** Test results *****\")\n",
    "        if pl_module.is_logger():\n",
    "            metrics = trainer.callback_metrics\n",
    "            # Log and save results to file\n",
    "            output_test_results_file = os.path.join(pl_module.config.output_dir, \"test_results.txt\")\n",
    "            with open(output_test_results_file, \"w\") as writer:\n",
    "                for key in sorted(metrics):\n",
    "                    if key not in [\"log\", \"progress_bar\"]:\n",
    "                        logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "                        writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ba0a247",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T18:30:44.254156Z",
     "iopub.status.busy": "2023-08-25T18:30:44.253133Z",
     "iopub.status.idle": "2023-08-25T18:30:44.277921Z",
     "shell.execute_reply": "2023-08-25T18:30:44.276736Z"
    },
    "id": "U9tLgD2O6oHl",
    "papermill": {
     "duration": 0.036847,
     "end_time": "2023-08-25T18:30:44.280700",
     "exception": false,
     "start_time": "2023-08-25T18:30:44.243853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath = config.output_dir, monitor=\"validation_epoch_average\", mode=\"max\", save_top_k=1\n",
    ")\n",
    "train_params = dict(\n",
    "    devices=config.n_gpu,\n",
    "    strategy=\"auto\",\n",
    "    accumulate_grad_batches=config.gradient_accumulation_steps,\n",
    "    accelerator=\"gpu\",\n",
    "    max_epochs=config.num_train_epochs,\n",
    "    precision= '16-mixed' if config.fp_16 else 32,\n",
    "    gradient_clip_val=config.max_grad_norm,\n",
    "    callbacks=[LoggingCallback(),checkpoint_callback,DeviceCallback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac4f09a",
   "metadata": {
    "id": "feB5OEdeoV91",
    "papermill": {
     "duration": 0.00763,
     "end_time": "2023-08-25T18:30:44.296480",
     "exception": false,
     "start_time": "2023-08-25T18:30:44.288850",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71eee3e",
   "metadata": {
    "id": "HjqZhSB8C0Qk",
    "papermill": {
     "duration": 0.007663,
     "end_time": "2023-08-25T18:30:44.312064",
     "exception": false,
     "start_time": "2023-08-25T18:30:44.304401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Coming to the most interesting part - the model architecture! We'll create a class named **Model**, inherited from **torch.nn.Module**.<br><br>\n",
    "\n",
    "### Flow\n",
    "- We initialize our pretrained T5 model with a Conditional Generation Head.\n",
    "- Pass in the src & tgt, input_ids & attention_mask.\n",
    "- The model returns the decoder generated output ids (predicted labels in textual format), which we need to decode further using the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbf28537",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T18:30:44.329705Z",
     "iopub.status.busy": "2023-08-25T18:30:44.329304Z",
     "iopub.status.idle": "2023-08-25T18:31:16.182502Z",
     "shell.execute_reply": "2023-08-25T18:31:16.179845Z"
    },
    "id": "PQrSW7puLOiN",
    "outputId": "18196e3e-675a-4012-e31c-cfe131cdf8ab",
    "papermill": {
     "duration": 31.875868,
     "end_time": "2023-08-25T18:31:16.195859",
     "exception": true,
     "start_time": "2023-08-25T18:30:44.319991",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.15.5)\r\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.3)\r\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.31)\r\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\r\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.27.1)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0)\r\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb) (0.1.2)\r\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.2)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (59.8.0)\r\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\r\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.5.7)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\r\n",
      "Collecting lightning\r\n",
      "  Downloading lightning-2.0.7-py3-none-any.whl (1.9 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: Jinja2<5.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (3.1.2)\r\n",
      "Requirement already satisfied: PyYAML<8.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (6.0)\r\n",
      "Requirement already satisfied: arrow<3.0,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.2.3)\r\n",
      "Requirement already satisfied: backoff<4.0,>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.2.1)\r\n",
      "Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.12.2)\r\n",
      "Requirement already satisfied: click<10.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (8.1.3)\r\n",
      "Collecting croniter<1.5.0,>=1.3.0 (from lightning)\r\n",
      "  Downloading croniter-1.4.1-py2.py3-none-any.whl (19 kB)\r\n",
      "Collecting dateutils<2.0 (from lightning)\r\n",
      "  Downloading dateutils-0.6.12-py2.py3-none-any.whl (5.7 kB)\r\n",
      "Collecting deepdiff<8.0,>=5.7.0 (from lightning)\r\n",
      "  Downloading deepdiff-6.3.1-py3-none-any.whl (70 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.7/70.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: fastapi<2.0,>=0.92.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.98.0)\r\n",
      "Requirement already satisfied: fsspec<2025.0,>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2023.6.0)\r\n",
      "Collecting inquirer<5.0,>=2.10.0 (from lightning)\r\n",
      "  Downloading inquirer-3.1.3-py3-none-any.whl (18 kB)\r\n",
      "Collecting lightning-cloud>=0.5.37 (from lightning)\r\n",
      "  Downloading lightning_cloud-0.5.37-py3-none-any.whl (596 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.7/596.7 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: lightning-utilities<2.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.9.0)\r\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.23.5)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from lightning) (21.3)\r\n",
      "Requirement already satisfied: psutil<7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (5.9.3)\r\n",
      "Requirement already satisfied: pydantic<2.2.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.10.9)\r\n",
      "Collecting python-multipart<2.0,>=0.0.5 (from lightning)\r\n",
      "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: requests<4.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.31.0)\r\n",
      "Requirement already satisfied: rich<15.0,>=12.3.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (13.4.2)\r\n",
      "Requirement already satisfied: starlette in /opt/conda/lib/python3.10/site-packages (from lightning) (0.27.0)\r\n",
      "Collecting starsessions<2.0,>=1.2.1 (from lightning)\r\n",
      "  Downloading starsessions-1.3.0-py3-none-any.whl (10 kB)\r\n",
      "Requirement already satisfied: torch<4.0,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.0.0+cpu)\r\n",
      "Requirement already satisfied: torchmetrics<2.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.0.0)\r\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.65.0)\r\n",
      "Requirement already satisfied: traitlets<7.0,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (5.9.0)\r\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.6.3)\r\n",
      "Requirement already satisfied: urllib3<4.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.26.15)\r\n",
      "Requirement already satisfied: uvicorn<2.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.22.0)\r\n",
      "Requirement already satisfied: websocket-client<3.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.6.0)\r\n",
      "Requirement already satisfied: websockets<13.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (11.0.3)\r\n",
      "Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning) (2.0.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from arrow<3.0,>=1.2.0->lightning) (2.8.2)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4<6.0,>=4.8.0->lightning) (2.3.2.post1)\r\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from dateutils<2.0->lightning) (2023.3)\r\n",
      "Collecting ordered-set<4.2.0,>=4.0.2 (from deepdiff<8.0,>=5.7.0->lightning)\r\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec<2025.0,>=2022.5.0->lightning) (3.8.4)\r\n",
      "Requirement already satisfied: blessed>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from inquirer<5.0,>=2.10.0->lightning) (1.20.0)\r\n",
      "Collecting python-editor>=1.0.4 (from inquirer<5.0,>=2.10.0->lightning)\r\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\r\n",
      "Collecting readchar>=3.0.6 (from inquirer<5.0,>=2.10.0->lightning)\r\n",
      "  Downloading readchar-4.0.5-py3-none-any.whl (8.5 kB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2<5.0->lightning) (2.1.3)\r\n",
      "Requirement already satisfied: pyjwt in /opt/conda/lib/python3.10/site-packages (from lightning-cloud>=0.5.37->lightning) (2.7.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from lightning-cloud>=0.5.37->lightning) (1.16.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->lightning) (3.0.9)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<4.0->lightning) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<4.0->lightning) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<4.0->lightning) (2023.5.7)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<15.0,>=12.3.0->lightning) (2.2.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<15.0,>=12.3.0->lightning) (2.15.1)\r\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette->lightning) (3.7.0)\r\n",
      "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from starsessions<2.0,>=1.2.1->lightning) (2.1.2)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (3.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (3.1)\r\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn<2.0->lightning) (0.14.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (23.1.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (4.0.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (1.3.3)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (1.3.1)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette->lightning) (1.3.0)\r\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette->lightning) (1.1.1)\r\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in /opt/conda/lib/python3.10/site-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning) (0.2.6)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<15.0,>=12.3.0->lightning) (0.1.2)\r\n",
      "Requirement already satisfied: setuptools>=41.0 in /opt/conda/lib/python3.10/site-packages (from readchar>=3.0.6->inquirer<5.0,>=2.10.0->lightning) (59.8.0)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<4.0,>=1.11.0->lightning) (1.3.0)\r\n",
      "Installing collected packages: python-editor, readchar, python-multipart, ordered-set, inquirer, deepdiff, dateutils, croniter, starsessions, lightning-cloud, lightning\r\n",
      "Successfully installed croniter-1.4.1 dateutils-0.6.12 deepdiff-6.3.1 inquirer-3.1.3 lightning-2.0.7 lightning-cloud-0.5.37 ordered-set-4.1.0 python-editor-1.0.4 python-multipart-0.0.6 readchar-4.0.5 starsessions-1.3.0\r\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">lightning.pytorch.loggers</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> WandbLogger                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>6 wandb_logger = WandbLogger(project=<span style=\"color: #808000; text-decoration-color: #808000\">\"HTarabT5\"</span>)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">7 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/lightning/pytorch/loggers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">wandb.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">359</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">356 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># start wandb run (to create an attach_id for distributed modes)</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">357 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> _WANDB_GREATER_EQUAL_0_12_10:                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">358 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>wandb.require(<span style=\"color: #808000; text-decoration-color: #808000\">\"service\"</span>)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>359 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>_ = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.experiment                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">360 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">361 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._checkpoint_name = checkpoint_name                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">362 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/lightning/fabric/loggers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">logger.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">118</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">experiment</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> rank_zero_only.rank &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>:                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _DummyExperiment()                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>118 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> fn(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>)                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">119 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">120 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> experiment                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/lightning/pytorch/loggers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">wandb.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">407</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">experiment</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">404 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._experiment = wandb._attach(attach_id)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">405 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">406 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># create new wandb process</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>407 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._experiment = wandb.init(**<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._wandb_init)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">408 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">409 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># define default x-axis</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">410 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._experiment, (Run, RunDisabled)) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">getattr</span>(           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/wandb/sdk/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">wandb_init.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1173</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">init</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1170 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> Error <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> e:                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1171 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> logger <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1172 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>logger.exception(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>(e))                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1173 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> e                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1174 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyboardInterrupt</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> e:                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1175 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> logger                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1176 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>logger.warning(<span style=\"color: #808000; text-decoration-color: #808000\">\"interrupted\"</span>, exc_info=e)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/wandb/sdk/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">wandb_init.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1150</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">init</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1147 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>run: Optional[Union[Run, RunDisabled]] = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1148 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1149 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>wi = _WandbInit()                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1150 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>wi.setup(kwargs)                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1151 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> wi.settings                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1152 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>except_exit = wi.settings._except_exit                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1153 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/wandb/sdk/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">wandb_init.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">289</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">setup</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 286 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>settings.update(init_settings, source=Source.INIT)                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 287 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 288 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> settings._offline <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> settings._noop:                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 289 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>wandb_login._login(                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 290 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>anonymous=kwargs.pop(<span style=\"color: #808000; text-decoration-color: #808000\">\"anonymous\"</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>),                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 291 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>force=kwargs.pop(<span style=\"color: #808000; text-decoration-color: #808000\">\"force\"</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>),                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 292 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>_disable_warning=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>,                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/wandb/sdk/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">wandb_login.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">298</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_login</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">295 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> logged_in                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">296 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">297 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> key:                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>298 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>wlogin.prompt_api_key()                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">299 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">300 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># make sure login credentials get to the backend</span>                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">301 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>wlogin.propogate_login()                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/wandb/sdk/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">wandb_login.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">228</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">prompt_api_key</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">225 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._settings._cli_only_mode                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">226 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"wandb.login(key=[your_api_key])\"</span>                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">227 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>228 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> UsageError(<span style=\"color: #808000; text-decoration-color: #808000\">\"api_key not configured (no-tty). call \"</span> + directive)         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">229 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">230 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.update_session(key, status=status)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">231 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._key = key                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">UsageError: </span>api_key not configured <span style=\"font-weight: bold\">(</span>no-tty<span style=\"font-weight: bold\">)</span>. call <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">wandb.login</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">key</span>=<span style=\"font-weight: bold\">[</span>your_api_key<span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m6\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96mlightning\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mpytorch\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mloggers\u001b[0m \u001b[94mimport\u001b[0m WandbLogger                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m6 wandb_logger = WandbLogger(project=\u001b[33m\"\u001b[0m\u001b[33mHTarabT5\u001b[0m\u001b[33m\"\u001b[0m)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m7 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/lightning/pytorch/loggers/\u001b[0m\u001b[1;33mwandb.py\u001b[0m:\u001b[94m359\u001b[0m in \u001b[92m__init__\u001b[0m       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m356 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# start wandb run (to create an attach_id for distributed modes)\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m357 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m _WANDB_GREATER_EQUAL_0_12_10:                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m358 \u001b[0m\u001b[2m│   │   │   \u001b[0mwandb.require(\u001b[33m\"\u001b[0m\u001b[33mservice\u001b[0m\u001b[33m\"\u001b[0m)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m359 \u001b[2m│   │   │   \u001b[0m_ = \u001b[96mself\u001b[0m.experiment                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m360 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m361 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._checkpoint_name = checkpoint_name                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m362 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/lightning/fabric/loggers/\u001b[0m\u001b[1;33mlogger.py\u001b[0m:\u001b[94m118\u001b[0m in \u001b[92mexperiment\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m rank_zero_only.rank > \u001b[94m0\u001b[0m:                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m _DummyExperiment()                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m118 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m fn(\u001b[96mself\u001b[0m)                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m119 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m120 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m experiment                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m121 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/lightning/pytorch/loggers/\u001b[0m\u001b[1;33mwandb.py\u001b[0m:\u001b[94m407\u001b[0m in \u001b[92mexperiment\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m404 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._experiment = wandb._attach(attach_id)                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m405 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m406 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# create new wandb process\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m407 \u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._experiment = wandb.init(**\u001b[96mself\u001b[0m._wandb_init)                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m408 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m409 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# define default x-axis\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m410 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(\u001b[96mself\u001b[0m._experiment, (Run, RunDisabled)) \u001b[95mand\u001b[0m \u001b[96mgetattr\u001b[0m(           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/wandb/sdk/\u001b[0m\u001b[1;33mwandb_init.py\u001b[0m:\u001b[94m1173\u001b[0m in \u001b[92minit\u001b[0m                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1170 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mexcept\u001b[0m Error \u001b[94mas\u001b[0m e:                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1171 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m logger \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1172 \u001b[0m\u001b[2m│   │   │   \u001b[0mlogger.exception(\u001b[96mstr\u001b[0m(e))                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1173 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m e                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1174 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mKeyboardInterrupt\u001b[0m \u001b[94mas\u001b[0m e:                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1175 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m logger                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1176 \u001b[0m\u001b[2m│   │   \u001b[0mlogger.warning(\u001b[33m\"\u001b[0m\u001b[33minterrupted\u001b[0m\u001b[33m\"\u001b[0m, exc_info=e)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/wandb/sdk/\u001b[0m\u001b[1;33mwandb_init.py\u001b[0m:\u001b[94m1150\u001b[0m in \u001b[92minit\u001b[0m                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1147 \u001b[0m\u001b[2m│   \u001b[0mrun: Optional[Union[Run, RunDisabled]] = \u001b[94mNone\u001b[0m                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1148 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mtry\u001b[0m:                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1149 \u001b[0m\u001b[2m│   │   \u001b[0mwi = _WandbInit()                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1150 \u001b[2m│   │   \u001b[0mwi.setup(kwargs)                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1151 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m wi.settings                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1152 \u001b[0m\u001b[2m│   │   \u001b[0mexcept_exit = wi.settings._except_exit                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1153 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/wandb/sdk/\u001b[0m\u001b[1;33mwandb_init.py\u001b[0m:\u001b[94m289\u001b[0m in \u001b[92msetup\u001b[0m                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 286 \u001b[0m\u001b[2m│   │   │   \u001b[0msettings.update(init_settings, source=Source.INIT)                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 287 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 288 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m settings._offline \u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m settings._noop:                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 289 \u001b[2m│   │   │   \u001b[0mwandb_login._login(                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 290 \u001b[0m\u001b[2m│   │   │   │   \u001b[0manonymous=kwargs.pop(\u001b[33m\"\u001b[0m\u001b[33manonymous\u001b[0m\u001b[33m\"\u001b[0m, \u001b[94mNone\u001b[0m),                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 291 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mforce=kwargs.pop(\u001b[33m\"\u001b[0m\u001b[33mforce\u001b[0m\u001b[33m\"\u001b[0m, \u001b[94mNone\u001b[0m),                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 292 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m_disable_warning=\u001b[94mTrue\u001b[0m,                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/wandb/sdk/\u001b[0m\u001b[1;33mwandb_login.py\u001b[0m:\u001b[94m298\u001b[0m in \u001b[92m_login\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m295 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m logged_in                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m296 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m297 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m key:                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m298 \u001b[2m│   │   \u001b[0mwlogin.prompt_api_key()                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m299 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m300 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# make sure login credentials get to the backend\u001b[0m                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m301 \u001b[0m\u001b[2m│   \u001b[0mwlogin.propogate_login()                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/wandb/sdk/\u001b[0m\u001b[1;33mwandb_login.py\u001b[0m:\u001b[94m228\u001b[0m in \u001b[92mprompt_api_key\u001b[0m           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m225 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._settings._cli_only_mode                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m226 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mwandb.login(key=[your_api_key])\u001b[0m\u001b[33m\"\u001b[0m                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m227 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m228 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m UsageError(\u001b[33m\"\u001b[0m\u001b[33mapi_key not configured (no-tty). call \u001b[0m\u001b[33m\"\u001b[0m + directive)         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m229 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m230 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.update_session(key, status=status)                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m231 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._key = key                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mUsageError: \u001b[0mapi_key not configured \u001b[1m(\u001b[0mno-tty\u001b[1m)\u001b[0m. call \u001b[1;35mwandb.login\u001b[0m\u001b[1m(\u001b[0m\u001b[33mkey\u001b[0m=\u001b[1m[\u001b[0myour_api_key\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install wandb\n",
    "!pip install lightning\n",
    "\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "wandb_logger = WandbLogger(project=\"HTarabT5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f01e00d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5436ea17",
   "metadata": {
    "id": "d1xG8CCdlgge",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class T5FineTuner(pl.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(config.model_name_or_path)\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(config.model_name_or_path)\n",
    "        #self.f1 = torchmetrics.F1()\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.test_step_outputs = []\n",
    "\n",
    "    def is_logger(self):\n",
    "        return self.trainer.global_rank  <= 0\n",
    "\n",
    "    def forward(\n",
    "        self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, labels=None\n",
    "        ):\n",
    "        return self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            labels=labels,\n",
    "            )\n",
    "\n",
    "    def _step(self, batch):\n",
    "        lm_labels = batch[\"target_ids\"]\n",
    "        lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
    "        outputs = self(\n",
    "        input_ids=batch[\"source_ids\"],\n",
    "        attention_mask=batch[\"source_mask\"],\n",
    "        labels=lm_labels,\n",
    "        decoder_attention_mask=batch['target_mask']\n",
    "        )\n",
    "        #print(outputs.shape)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "        self.log(\"train/loss\", loss)\n",
    "        self.training_step_outputs.append(loss)\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        epoch_average = torch.stack(self.training_step_outputs).mean()\n",
    "        self.log(\"training_epoch_average\", epoch_average, sync_dist=True, prog_bar=True, logger=True, on_epoch=True)\n",
    "        self.training_step_outputs.clear()  # free memory\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "        self.test_step_outputs.append(loss)\n",
    "        return loss\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        epoch_average = torch.stack(self.test_step_outputs).mean()\n",
    "        self.log(\"test_epoch_average\", epoch_average, sync_dist=True, prog_bar=True, logger=True, on_epoch=True)\n",
    "        self.test_step_outputs.clear()  # free memory\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "        #y = batch['target_ids'].clone().detach()\n",
    "        #lm_labels = y.clone().detach()\n",
    "        #lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
    "        self.validation_step_outputs.append(loss)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        epoch_average = torch.stack(self.validation_step_outputs).mean()\n",
    "        self.log(\"validation_epoch_average\", epoch_average, sync_dist=True, prog_bar=True, logger=True, on_epoch=True)\n",
    "        self.validation_step_outputs.clear()  # free memory\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
    "\n",
    "        model = self.model\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "\n",
    "        optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": self.config.weight_decay,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=self.config.learning_rate, eps=self.config.adam_epsilon)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=self.config.warmup_steps, num_training_steps=self.trainer.estimated_stepping_batches)\n",
    "        self.lr_scheduler = scheduler\n",
    "        scheduler = {\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}\n",
    "        return [optimizer],[scheduler]\n",
    "\n",
    "    def get_tqdm_dict(self):\n",
    "        tqdm_dict = {\"loss\": \"{:.3f}\".format(self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n",
    "        return tqdm_dict\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataset = get_dataset(config=self.config, tokenizer=self.tokenizer, part=\"train\")\n",
    "        return DataLoader(train_dataset, batch_size=self.config.train_batch_size, drop_last=True, shuffle=True,num_workers=2,pin_memory=True)\n",
    "    def val_dataloader(self):\n",
    "        val_dataset = get_dataset(config=self.config,tokenizer=self.tokenizer, part=\"val\")\n",
    "        return DataLoader(val_dataset, batch_size=self.config.eval_batch_size, num_workers=2,pin_memory=True)\n",
    "    def test_dataloader(self):\n",
    "        val_dataset = get_dataset(config=self.config,tokenizer=self.tokenizer, part=\"test\")\n",
    "        return DataLoader(val_dataset, batch_size=self.config.eval_batch_size, num_workers=2,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87b6095",
   "metadata": {
    "id": "jiypz6jrG9bl",
    "outputId": "d16d6835-314f-4c02-842f-0962de051474",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = T5FineTuner(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a61166a",
   "metadata": {
    "id": "mlsnd6mu6oHn",
    "outputId": "dfe6f12c-9dda-483b-b4e8-5f8056df362b",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(**train_params,overfit_batches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41e8f1c",
   "metadata": {
    "id": "iZ59dtmH6oHo",
    "outputId": "b6530313-d689-4dc7-829e-24b7c9c333e6",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef2b348",
   "metadata": {
    "id": "QEVJPRXWgnZw",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(config.model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd83d29",
   "metadata": {
    "id": "ihFL9T55h4ss",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model = T5FineTuner.load_from_checkpoint(\"/content/logs/epoch=9-step=80.ckpt\",config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcf43cc",
   "metadata": {
    "id": "MEa00VKtVQq-",
    "outputId": "1df2ef83-00d2-4fd1-ddc5-8cfe603f9a7f",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "outputs = []\n",
    "targets = []\n",
    "for batch in tqdm(loader):\n",
    "    outs = model.model.generate(input_ids=batch['source_ids'].cuda(),\n",
    "                              attention_mask=batch['source_mask'].cuda(),\n",
    "                              max_length=2)\n",
    "\n",
    "    dec = [tokenizer.decode(ids[ids > 1 ]) for ids in outs]\n",
    "    target = [tokenizer.decode((ids[ids > 1 ])) for ids in batch[\"target_ids\"]]\n",
    "\n",
    "    outputs.extend(dec)\n",
    "    targets.extend(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64607bf1",
   "metadata": {
    "id": "hCOjxCSbVSY2",
    "outputId": "6f3cc0be-79dc-4cbb-8fba-f1bcfd7df838",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(targets, outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbaa9b0",
   "metadata": {
    "id": "3gqbs7XaECCm",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20302c78",
   "metadata": {
    "id": "7sw2flRKD-Ee",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(32):\n",
    "    lines = textwrap.wrap(\"Review:\\n%s\\n\" % texts[i], width=100)\n",
    "    print(\"\\n\".join(lines))\n",
    "    print(\"\\nActual sentiment: %s\" % targets[i])\n",
    "    print(\"Predicted sentiment: %s\" % dec[i])\n",
    "    print(\"=====================================================================\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 109.639785,
   "end_time": "2023-08-25T18:31:19.526699",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-25T18:29:29.886914",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
