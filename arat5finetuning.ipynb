{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### [T5](https://github.com/google-research/text-to-text-transfer-transformer)\n- **Text-To-Text Transfer Transformer**\n- A unified framework that converts every language problem into a text-to-text format.\n- Achieves state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more.\n\n### Multi Class vs Multi Label Classification\n- **Multi Class** - There are multiple categories but each instance is assigned only one, therefore such problems are known as multi-class classification problem.","metadata":{"id":"buleZD1j2kLm"}},{"cell_type":"markdown","source":"# Imports","metadata":{"id":"vr-nvX_HT4_K"}},{"cell_type":"markdown","source":"The entire code is written using **PyTorch**.<br>\nWe'll be using the **transformers** library by [huggingface](https://github.com/huggingface/transformers) as they provide wrappers for multiple Transformer models.","metadata":{"id":"GqOpA5x73pYs"}},{"cell_type":"code","source":"%%capture\n\n!pip install transformers\n!pip install pytorch-lightning --upgrade\n!pip install sentencepiece\n!pip install datasets --upgrade\n!pip install torchmetrics\n!pip install wandb\n!pip install lightning\n!!pip install optuna\n","metadata":{"id":"9J7Ws11-9PqG","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''rom google.colab import files\n\nfiles.upload()\n! mkdir ~/.kaggle\n! cp kaggle.json ~/.kaggle/\n! chmod 600 ~/.kaggle/kaggle.json\n! kaggle datasets download -d sifalklioui/hatespeechdza\n!mkdir data\n!unzip hatespeechdza.zip -d ./data'''","metadata":{"id":"61f6obyD_Kud","outputId":"63cd297c-7f38-4c70-d1fa-1b644585edc1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2","metadata":{"execution":{"iopub.status.busy":"2023-08-29T14:37:03.263403Z","iopub.execute_input":"2023-08-29T14:37:03.263770Z","iopub.status.idle":"2023-08-29T14:37:03.315447Z","shell.execute_reply.started":"2023-08-29T14:37:03.263734Z","shell.execute_reply":"2023-08-29T14:37:03.314403Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset as hgdataset\nfrom datasets import load_dataset\nimport numpy as np\nimport pickle\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport copy\nfrom tqdm.notebook import tqdm\nimport gc\nimport random\nimport torch\nimport wandb\nimport torchmetrics\nimport logging\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom dataclasses import dataclass\nfrom sklearn.metrics import f1_score\nimport pytorch_lightning as pl\nfrom torch.optim import AdamW\nfrom torchmetrics import Metric\nfrom lightning.pytorch.loggers import WandbLogger\nimport optuna\nfrom optuna.integration import PyTorchLightningPruningCallback\nfrom optuna.trial import TrialState\n\nfrom transformers import (\n    T5Tokenizer,\n    T5Model,\n    T5ForConditionalGeneration,\n    get_linear_schedule_with_warmup\n)\nwandb.login(key=\"902ffdfbd80732219ee9853892860a048fa9914f\")\nwandb_logger = WandbLogger(project=\"HTarabT5\")","metadata":{"id":"07GPLpCt_AjQ","execution":{"iopub.status.busy":"2023-08-29T14:37:06.207912Z","iopub.execute_input":"2023-08-29T14:37:06.208274Z","iopub.status.idle":"2023-08-29T14:37:48.886560Z","shell.execute_reply.started":"2023-08-29T14:37:06.208237Z","shell.execute_reply":"2023-08-29T14:37:48.885534Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msifalklioui\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.9 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>./wandb/run-20230829_143717-f8ot9nk9</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/sifalklioui/HTarabT5/runs/f8ot9nk9' target=\"_blank\">kind-hill-54</a></strong> to <a href='https://wandb.ai/sifalklioui/HTarabT5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/sifalklioui/HTarabT5' target=\"_blank\">https://wandb.ai/sifalklioui/HTarabT5</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/sifalklioui/HTarabT5/runs/f8ot9nk9' target=\"_blank\">https://wandb.ai/sifalklioui/HTarabT5/runs/f8ot9nk9</a>"},"metadata":{}}]},{"cell_type":"code","source":"@dataclass\nclass Config:\n    seed = 203\n    data_folder = \"../input/hatespeechdza\"\n    output_dir = './logs'\n    model_name_or_path = 'UBC-NLP/AraT5v2-base-1024'\n    src_max_length = 40\n    tgt_max_length = 2\n    add_special_tokens = True\n    truncation = True\n    return_tensors = 'pt'\n    padding = \"max_length\"\n    weight_decay=0.0\n    adam_epsilon=1e-8\n    warmup_steps=0\n    train_batch_size=32\n    eval_batch_size=32\n    num_train_epochs=5\n    gradient_accumulation_steps=16\n    n_gpu=1\n    fp_16= True, # if you want to enable 16-bit training then install apex and set this to true\n    max_grad_norm=0.5 # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n    learning_rate= float(3e-4)\n\nconfig = Config()\n\ndef set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\nset_seed(config.seed)","metadata":{"id":"281L6wVJ6oHj","execution":{"iopub.status.busy":"2023-08-29T14:37:48.888631Z","iopub.execute_input":"2023-08-29T14:37:48.889871Z","iopub.status.idle":"2023-08-29T14:37:49.064685Z","shell.execute_reply.started":"2023-08-29T14:37:48.889832Z","shell.execute_reply":"2023-08-29T14:37:49.063764Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Dataset & Dataloader","metadata":{"id":"e1AhmXnXByg5"}},{"cell_type":"markdown","source":"Now, we'll create a custom Dataset class inherited from the PyTorch Dataset class. We'll be using the **T5 tokenizer** that returns **input_ids** and **attention_mask**.<br><br>\nThe custom Dataset class will return a dict containing - <br>\n\n- src_input_ids\n- src_attention_mask\n- tgt_input_ids'\n-tgt_attention_mask","metadata":{"id":"cwrzxPV8B1Es"}},{"cell_type":"code","source":"class HateDetect():\n    def __init__(self,config,tokenizer, part):\n\n        self.config = config\n        self.part = part\n        self.tokenizer = tokenizer\n\n\n        data_paths = {\n            'train': config.data_folder + \"/dataset_prep_train.csv\",\n            'test': config.data_folder + \"/dataset_prep_test.csv\",\n            'val': config.data_folder + \"/dataset_prep_val.csv\"\n        }\n        path = data_paths.get(self.part,None)\n        if path is not None:\n            df = pd.read_csv(path)\n            df['label'].replace({0:\"normal\",1:\"hate\"}, inplace = True)\n            self.data = hgdataset.from_pandas(df ,split=self.part)\n        else:\n            raise ValueError(\"Invalid value for self.part\")\n\n\n        self.dataset_scr,self.dataset_tgt = self.tokenize()\n\n        # create funtion to tokenize data\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self,idx):\n\n        source_ids = self.dataset_scr[\"input_ids\"][idx].squeeze()\n        target_ids = self.dataset_tgt[\"input_ids\"][idx].squeeze()\n\n        src_mask    = self.dataset_scr[\"attention_mask\"][idx].squeeze()\n        target_mask = self.dataset_tgt[\"attention_mask\"][idx].squeeze()\n\n        return {\"source_ids\": source_ids,\n                \"source_mask\": src_mask,\n                \"target_ids\": target_ids,\n                \"target_mask\": target_mask}\n\n\n    def tokenize(self):\n\n        tokenizer_params = {\n            \"src\": {\n                \"max_length\": self.config.src_max_length,\n                \"add_special_tokens\": self.config.add_special_tokens,\n                \"truncation\": self.config.truncation,\n                \"return_tensors\": self.config.return_tensors,\n                \"padding\": self.config.padding\n            },\n            \"tgt\": {\n                \"max_length\": self.config.tgt_max_length,\n                \"add_special_tokens\": self.config.add_special_tokens,\n                \"truncation\": self.config.truncation,\n                \"return_tensors\": self.config.return_tensors,\n                \"padding\": self.config.padding\n            }\n        }\n        dataset_scr = self.tokenizer(self.data['text'], **tokenizer_params[\"src\"])\n        dataset_tgt = self.tokenizer(self.data['label'], **tokenizer_params[\"tgt\"])\n        return dataset_scr,dataset_tgt\n\ndef get_dataset(config,tokenizer,part):\n    return HateDetect(config,tokenizer,part)","metadata":{"id":"w0D46GkV6oHl","execution":{"iopub.status.busy":"2023-08-29T14:37:49.066334Z","iopub.execute_input":"2023-08-29T14:37:49.066995Z","iopub.status.idle":"2023-08-29T14:37:49.234489Z","shell.execute_reply.started":"2023-08-29T14:37:49.066960Z","shell.execute_reply":"2023-08-29T14:37:49.233567Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"logger = logging.getLogger(__name__)\n\nclass DeviceCallback(pl.Callback):\n    def on_batch_start(self, trainer, pl_module):\n        assert next(pl_module.parameters()).device.type == \"cuda\"\n\nclass LoggingCallback(pl.Callback):\n    def on_validation_end(self, trainer, pl_module):\n        logger.info(\"***** Validation results *****\")\n        if pl_module.is_logger():\n            metrics = trainer.callback_metrics\n            # Log results\n            for key in sorted(metrics):\n                if key not in [\"log\", \"progress_bar\"]:\n                    logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))","metadata":{"id":"BGVTpK7g6oHl","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    def on_test_end(self, trainer, pl_module):\n        logger.info(\"***** Validation results *****\")\n        if pl_module.is_logger():\n            metrics = trainer.callback_metrics\n            # Log results\n            for key in sorted(metrics):\n                if key not in [\"log\", \"progress_bar\"]:\n                    logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks=[DeviceCallback()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_callback = pl.callbacks.ModelCheckpoint(\n    dirpath= config.output_dir, monitor=\"f1_valid_epoch\", mode=\"max\", save_top_k=1)\n    \n#dc = pl.callbacks.DeviceStatsMonitor(cpu_stats=True)\n\ntrain_params = dict(\n    devices=config.n_gpu,\n    strategy=\"auto\",\n    accelerator=\"gpu\",\n    max_epochs=config.num_train_epochs+10,\n    precision= \"16-mixed\" if config.fp_16 else \"32\",\n    gradient_clip_val=config.max_grad_norm,\n    callbacks=[checkpoint_callback]\n)","metadata":{"id":"U9tLgD2O6oHl","execution":{"iopub.status.busy":"2023-08-29T14:55:13.147395Z","iopub.execute_input":"2023-08-29T14:55:13.147781Z","iopub.status.idle":"2023-08-29T14:55:13.277450Z","shell.execute_reply.started":"2023-08-29T14:55:13.147751Z","shell.execute_reply":"2023-08-29T14:55:13.276408Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"LoggingCallback(),checkpoint_callback,    callbacks=[checkpoint_callback]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"feB5OEdeoV91"}},{"cell_type":"markdown","source":"Coming to the most interesting part - the model architecture! We'll create a class named **Model**, inherited from **torch.nn.Module**.<br><br>\n\n### Flow\n- We initialize our pretrained T5 model with a Conditional Generation Head.\n- Pass in the src & tgt, input_ids & attention_mask.\n- The model returns the decoder generated output ids (predicted labels in textual format), which we need to decode further using the tokenizer.","metadata":{"id":"HjqZhSB8C0Qk"}},{"cell_type":"code","source":"rm -r /kaggle/working/lightning_logs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FRP(Metric):\n    def __init__(self):\n        super().__init__()\n        higher_is_better = True\n        self.add_state(\"true_positives\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n        self.add_state(\"false_positives\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n        self.add_state(\"false_negatives\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n\n    def update(self, preds, target):\n        assert preds.shape == target.shape\n\n        self.true_positives += torch.sum((preds == 52459) & (target == 52459))\n        self.false_positives += torch.sum((preds == 52459) & (target == 16147))\n        self.false_negatives += torch.sum((preds == 16147) & (target == 52459))\n\n    def compute(self):\n        precision = self.true_positives.float() / (self.true_positives + self.false_positives).float()\n        recall = self.true_positives.float() / (self.true_positives + self.false_negatives).float()\n\n        f1_score = 2 * (precision * recall) / (precision + recall)\n        return f1_score, recall, precision\n","metadata":{"execution":{"iopub.status.busy":"2023-08-29T14:37:49.400429Z","iopub.execute_input":"2023-08-29T14:37:49.401054Z","iopub.status.idle":"2023-08-29T14:37:49.562704Z","shell.execute_reply.started":"2023-08-29T14:37:49.401020Z","shell.execute_reply":"2023-08-29T14:37:49.561773Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class MyAccuracy(Metric):\n    def __init__(self):\n        super().__init__()\n        higher_is_better = True\n        self.add_state(\"correct\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n        self.add_state(\"total\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n\n    def update(self, preds, target):\n        assert preds.shape == target.shape\n\n        self.correct += torch.sum(preds == target)\n        self.total += target.numel()\n\n    def compute(self):\n        return self.correct.float() / self.total","metadata":{"execution":{"iopub.status.busy":"2023-08-29T14:37:49.564395Z","iopub.execute_input":"2023-08-29T14:37:49.565084Z","iopub.status.idle":"2023-08-29T14:37:49.723328Z","shell.execute_reply.started":"2023-08-29T14:37:49.565047Z","shell.execute_reply":"2023-08-29T14:37:49.722414Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class T5FineTuner(pl.LightningModule):\n    def __init__(self, config):\n        super().__init__()\n        gc.collect()\n        torch.cuda.empty_cache() \n        self.config = config\n        self.model = T5ForConditionalGeneration.from_pretrained(config.model_name_or_path)\n        self.tokenizer = T5Tokenizer.from_pretrained(config.model_name_or_path)\n        self.valid_acc = MyAccuracy()\n        self.FRP = FRP()\n        self.training_step_outputs = []\n        self.validation_step_outputs = []\n\n    def forward(\n        self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, labels=None\n        ):\n        return self.model(\n            input_ids,\n            attention_mask=attention_mask,\n            decoder_input_ids=decoder_input_ids,\n            decoder_attention_mask=decoder_attention_mask,\n            labels=labels,\n            )\n\n    def _step(self, batch):\n        lm_labels = batch[\"target_ids\"]\n        lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n        outputs = self(\n        input_ids=batch[\"source_ids\"],\n        attention_mask=batch[\"source_mask\"],\n        labels=lm_labels,\n        decoder_attention_mask=batch['target_mask']\n        )\n        del lm_labels\n        return outputs[0]\n\n    def training_step(self, batch, batch_idx):\n        loss = self._step(batch)\n        #self.log(\"train/loss\", loss)\n        self.training_step_outputs.append(loss.item())\n        return loss\n\n    def on_train_epoch_end(self):\n        \n        self.log(\"training_epoch_average\", np.mean(self.training_step_outputs), sync_dist=True, prog_bar=True, logger=True, on_epoch=True)\n        self.training_step_outputs.clear()  # free memory\n        \n    def validation_step(self, batch, batch_idx):\n        \n        pred_ids = self.model.generate(input_ids=batch['source_ids'],\n                                       attention_mask=batch['source_mask'],\n                                       max_length=2)\n        \n        target_ids = batch['target_ids'][:,0].flatten()\n        self.valid_acc.update(pred_ids[:,1].flatten(),target_ids)\n        self.FRP.update(pred_ids[:,1].flatten(),target_ids)\n        del pred_ids\n        del target_ids\n        \n    def on_validation_epoch_end(self):\n        f1, recall, precision = self.FRP.compute()\n        self.log(\"acc_valid_epoch\", self.valid_acc.compute(), sync_dist=True, prog_bar=True, logger=True, on_epoch=True)\n        self.log(\"f1_valid_epoch\", f1, sync_dist=True, prog_bar=True, logger=True, on_epoch=True)  \n        self.log(\"recall_valid_epoch\", recall, sync_dist=True, prog_bar=True, logger=True, on_epoch=True) \n        self.log(\"precision_valid_epoch\", precision, sync_dist=True, prog_bar=True, logger=True, on_epoch=True) \n        self.valid_acc.reset()\n        self.FRP.reset()\n        del f1\n        del recall\n        del precision\n    def configure_optimizers(self):\n        \"Prepare optimizer and schedule (linear warmup and decay)\"\n\n        no_decay = [\"bias\", \"LayerNorm.weight\"]\n\n        optimizer_grouped_parameters = [\n        {\n            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n            \"weight_decay\": self.config.weight_decay,\n        },\n        {\n            \"params\": [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)],\n            \"weight_decay\": 0.0,\n        },\n        ]\n        optimizer = AdamW(optimizer_grouped_parameters, lr=self.config.learning_rate, eps=self.config.adam_epsilon)\n        scheduler = get_linear_schedule_with_warmup(\n        optimizer, num_warmup_steps=self.config.warmup_steps, num_training_steps=self.trainer.estimated_stepping_batches)\n\n        return [optimizer],[scheduler]\n\n\n    def train_dataloader(self):\n        return DataLoader(get_dataset(config=self.config, tokenizer=self.tokenizer, part=\"train\"), batch_size=self.config.train_batch_size, drop_last=True, shuffle=True,num_workers=0)\n    def val_dataloader(self):\n        return DataLoader(get_dataset(config=self.config,tokenizer=self.tokenizer, part=\"val\"), batch_size=self.config.eval_batch_size, drop_last=True,num_workers=0)\n","metadata":{"id":"d1xG8CCdlgge","_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-08-29T14:37:49.725141Z","iopub.execute_input":"2023-08-29T14:37:49.725873Z","iopub.status.idle":"2023-08-29T14:37:50.047268Z","shell.execute_reply.started":"2023-08-29T14:37:49.725838Z","shell.execute_reply":"2023-08-29T14:37:50.046138Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def test_dataloader(self):\n    val_dataset = get_dataset(config=self.config,tokenizer=self.tokenizer, part=\"test\")\n    return DataLoader(val_dataset, batch_size=self.config.eval_batch_size,drop_last=True, num_workers=1)\ndef test_step(self, batch, batch_idx):\n        loss = self._step(batch)\n        self.test_step_outputs.append(loss)\n        return loss\n\ndef on_test_epoch_end(self):\n    epoch_average = torch.stack(self.test_step_outputs).mean()\n    self.log(\"test_epoch_average\", epoch_average,  sync_dist=True, prog_bar=True, logger=True, on_epoch=True)\n    self.test_step_outputs.clear()  # free memory\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = T5FineTuner(config)","metadata":{"id":"jiypz6jrG9bl","outputId":"d16d6835-314f-4c02-842f-0962de051474","execution":{"iopub.status.busy":"2023-08-29T14:56:24.816871Z","iopub.execute_input":"2023-08-29T14:56:24.817255Z","iopub.status.idle":"2023-08-29T14:56:31.411889Z","shell.execute_reply.started":"2023-08-29T14:56:24.817216Z","shell.execute_reply":"2023-08-29T14:56:31.410731Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"trainer = pl.Trainer(**train_params,logger=WandbLogger)","metadata":{"id":"mlsnd6mu6oHn","outputId":"dfe6f12c-9dda-483b-b4e8-5f8056df362b","execution":{"iopub.status.busy":"2023-08-29T14:55:47.797443Z","iopub.execute_input":"2023-08-29T14:55:47.797876Z","iopub.status.idle":"2023-08-29T14:55:48.517544Z","shell.execute_reply.started":"2023-08-29T14:55:47.797840Z","shell.execute_reply":"2023-08-29T14:55:48.516523Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"INFO: Using 16bit Automatic Mixed Precision (AMP)\nINFO: GPU available: True (cuda), used: True\nINFO: TPU available: False, using: 0 TPU cores\nINFO: IPU available: False, using: 0 IPUs\nINFO: HPU available: False, using: 0 HPUs\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.fit(model)","metadata":{"id":"iZ59dtmH6oHo","outputId":"b6530313-d689-4dc7-829e-24b7c9c333e6","execution":{"iopub.status.busy":"2023-08-29T14:56:33.285496Z","iopub.execute_input":"2023-08-29T14:56:33.285894Z","iopub.status.idle":"2023-08-29T15:14:43.355809Z","shell.execute_reply.started":"2023-08-29T14:56:33.285865Z","shell.execute_reply":"2023-08-29T15:14:43.354615Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /kaggle/working/logs exists and is not empty.\n  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\nINFO: Loading `train_dataloader` to estimate number of stepping batches.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58c2e990509b4a7d92914e3e71e078a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"INFO: `Trainer.fit` stopped: `max_epochs=15` reached.\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = T5Tokenizer.from_pretrained(config.model_name_or_path)","metadata":{"id":"QEVJPRXWgnZw","execution":{"iopub.status.busy":"2023-08-29T14:53:24.575945Z","iopub.execute_input":"2023-08-29T14:53:24.576394Z","iopub.status.idle":"2023-08-29T14:53:24.848914Z","shell.execute_reply.started":"2023-08-29T14:53:24.576334Z","shell.execute_reply":"2023-08-29T14:53:24.847797Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"data_ = HateDetect(config,tokenizer=tokenizer, part=\"val\")\nloader = DataLoader(data_, batch_size=config.eval_batch_size,drop_last=True, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2023-08-29T14:54:36.383382Z","iopub.execute_input":"2023-08-29T14:54:36.383768Z","iopub.status.idle":"2023-08-29T14:54:37.289657Z","shell.execute_reply.started":"2023-08-29T14:54:36.383738Z","shell.execute_reply":"2023-08-29T14:54:37.288514Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import glob\n\n# Define the path pattern\npath_pattern = '/kaggle/working/logs/*'\n\n# Use glob to list files matching the pattern\nfile_list = glob.glob(path_pattern)\n\n# Print the list of matching files\nfor file_path in file_list:\n    print(file_path)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-29T14:52:29.894179Z","iopub.execute_input":"2023-08-29T14:52:29.894589Z","iopub.status.idle":"2023-08-29T14:52:30.031783Z","shell.execute_reply.started":"2023-08-29T14:52:29.894555Z","shell.execute_reply":"2023-08-29T14:52:30.030226Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"/kaggle/working/logs/epoch=8-step=1404.ckpt\n","output_type":"stream"}]},{"cell_type":"code","source":"path = \"/kaggle/working/logs/epoch=8-step=1404.ckpt\"\nmodel_test = T5FineTuner.load_from_checkpoint(path,config=config)\n\n# disable randomness, dropout, etc...\nmodel_test.eval()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputs = []\ntargets = []\nwith torch.no_grad():\n    for batch in tqdm(loader):\n        outs = model_test.model.generate(input_ids=batch['source_ids'].cuda(),\n                                  attention_mask=batch['source_mask'].cuda(),\n                                  max_length=2)\n\n        dec = [tokenizer.decode(ids[ids > 1 ]) for ids in outs]\n        target = [tokenizer.decode((ids[ids > 1 ])) for ids in batch[\"target_ids\"]]\n\n        outputs.extend(dec)\n        targets.extend(target)","metadata":{"id":"MEa00VKtVQq-","outputId":"1df2ef83-00d2-4fd1-ddc5-8cfe603f9a7f","execution":{"iopub.status.busy":"2023-08-29T14:54:40.532532Z","iopub.execute_input":"2023-08-29T14:54:40.532910Z","iopub.status.idle":"2023-08-29T14:54:47.188632Z","shell.execute_reply.started":"2023-08-29T14:54:40.532879Z","shell.execute_reply":"2023-08-29T14:54:47.187415Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/52 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2619988781514d6dbdeaadec932eb79a"}},"metadata":{}}]},{"cell_type":"code","source":"from sklearn import metrics","metadata":{"execution":{"iopub.status.busy":"2023-08-29T14:54:08.080164Z","iopub.execute_input":"2023-08-29T14:54:08.080565Z","iopub.status.idle":"2023-08-29T14:54:08.213503Z","shell.execute_reply.started":"2023-08-29T14:54:08.080530Z","shell.execute_reply":"2023-08-29T14:54:08.209571Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"print(metrics.classification_report(targets, outputs))","metadata":{"id":"hCOjxCSbVSY2","outputId":"6f3cc0be-79dc-4cbb-8fba-f1bcfd7df838","execution":{"iopub.status.busy":"2023-08-29T14:54:48.598438Z","iopub.execute_input":"2023-08-29T14:54:48.598820Z","iopub.status.idle":"2023-08-29T14:54:48.792137Z","shell.execute_reply.started":"2023-08-29T14:54:48.598790Z","shell.execute_reply":"2023-08-29T14:54:48.791076Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        hate       0.82      0.81      0.82      1068\n      normal       0.86      0.87      0.86      1428\n\n    accuracy                           0.84      2496\n   macro avg       0.84      0.84      0.84      2496\nweighted avg       0.84      0.84      0.84      2496\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import textwrap","metadata":{"id":"3gqbs7XaECCm","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(32):\n    lines = textwrap.wrap(\"Review:\\n%s\\n\" % texts[i], width=100)\n    print(\"\\n\".join(lines))\n    print(\"\\nActual sentiment: %s\" % targets[i])\n    print(\"Predicted sentiment: %s\" % dec[i])\n    print(\"=====================================================================\\n\")","metadata":{"id":"7sw2flRKD-Ee","trusted":true},"execution_count":null,"outputs":[]}]}